{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "038d22d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.50.0)\n",
      "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (6.2.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (8.3.0)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (2.3.4)\n",
      "Requirement already satisfied: packaging<26,>=20 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from streamlit) (25.0)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (2.3.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (11.3.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (6.33.0)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (21.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (2.32.5)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (4.15.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (3.1.45)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from streamlit) (6.5.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.8.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from seaborn) (2.3.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from seaborn) (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: plotly in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (6.3.1)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from plotly) (2.8.0)\n",
      "Requirement already satisfied: packaging in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from plotly) (25.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: statsmodels in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.14.5)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from statsmodels) (2.3.4)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from statsmodels) (1.16.2)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from statsmodels) (2.3.3)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from statsmodels) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K\n",
      "up to date, audited 23 packages in 897ms\n",
      "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K\n",
      "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K3 packages are looking for funding\n",
      "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K  run `npm fund` for details\n",
      "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K\n",
      "2 \u001b[31m\u001b[1mhigh\u001b[22m\u001b[39m severity vulnerabilities\n",
      "\n",
      "To address all issues (including breaking changes), run:\n",
      "  npm audit fix --force\n",
      "\n",
      "Run `npm audit` for details.\n",
      "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K"
     ]
    }
   ],
   "source": [
    "%pip install streamlit\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install scikit-learn\n",
    "%pip install plotly\n",
    "%pip install statsmodels\n",
    "\n",
    "#Para instalar npm en visual studio\n",
    "#1.Desde Google escribir node.js\n",
    "#2. Instalar la versión más recomendada\n",
    "! npm install localtunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d5e50a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting EVIDENCIA_2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile EVIDENCIA_2.py\n",
    "\n",
    "## streamlit run EVIDENCIA_2.py\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    r2_score, mean_absolute_error, mean_squared_error,\n",
    "    precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, roc_curve\n",
    ")\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# =========================\n",
    "# Utilidades base\n",
    "# =========================\n",
    "def safe_read_csv(path):\n",
    "    try:\n",
    "        if os.path.exists(path):\n",
    "            return pd.read_csv(path)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def unify_schema(df, city_name=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Normaliza nombres, resuelve columnas duplicadas, agrega 'city',\n",
    "    y convierte strings con '%' a numéricos. Evita AttributeError.\n",
    "    \"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        return None\n",
    "\n",
    "    # 1) Normaliza nombres a snake_case\n",
    "    cols_raw = list(df.columns)\n",
    "    norm_cols = [str(c).strip().lower().replace(\" \", \"_\") for c in cols_raw]\n",
    "\n",
    "    # 2) Unifica duplicados: col, col__1, col__2, ...\n",
    "    seen = {}\n",
    "    unique_cols = []\n",
    "    dups = []\n",
    "    for c in norm_cols:\n",
    "        if c not in seen:\n",
    "            seen[c] = 0\n",
    "            unique_cols.append(c)\n",
    "        else:\n",
    "            seen[c] += 1\n",
    "            new_c = f\"{c}__{seen[c]}\"\n",
    "            unique_cols.append(new_c)\n",
    "            dups.append((c, new_c))\n",
    "    if verbose and dups:\n",
    "        print(\"Columnas duplicadas renombradas:\", dups)\n",
    "\n",
    "    df = df.copy()\n",
    "    df.columns = unique_cols\n",
    "\n",
    "    # 3) Correcciones habituales\n",
    "    ren = {\n",
    "        \"accomodates\": \"accommodates\",\n",
    "        \"bedroms\": \"bedrooms\",\n",
    "        \"bathroom\": \"bathrooms\",\n",
    "        \"host_response_time(%)\": \"host_response_rate\",\n",
    "        \"review_scores_value\": \"review_scores_rating\"\n",
    "    }\n",
    "    for k, v in ren.items():\n",
    "        if k in df.columns and v not in df.columns:\n",
    "            df.rename(columns={k: v}, inplace=True)\n",
    "\n",
    "    # 4) Asegura 'city'\n",
    "    if \"city\" not in df.columns:\n",
    "        df[\"city\"] = city_name if city_name else \"unknown\"\n",
    "    else:\n",
    "        if city_name:\n",
    "            df[\"city\"] = df[\"city\"].fillna(city_name).replace(\"\", city_name)\n",
    "\n",
    "    # 5) Convierte columnas con símbolo %\n",
    "    for c in df.columns:\n",
    "        s = df[c]\n",
    "        if pd.api.types.is_object_dtype(s):\n",
    "            if s.astype(str).str.contains(\"%\").any():\n",
    "                s2 = s.astype(str).str.replace(\"%\", \"\", regex=False)\n",
    "                s2 = pd.to_numeric(s2, errors=\"coerce\")\n",
    "                df[c] = s2\n",
    "\n",
    "    return df\n",
    "\n",
    "def numeric_cols(df):\n",
    "    return [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "def categorical_cols(df):\n",
    "    return [c for c in df.columns if (df[c].dtype == \"object\" or str(df[c].dtype).startswith(\"category\"))]\n",
    "\n",
    "def r_from_y_ypred(y_true, y_pred):\n",
    "    if len(y_true) < 2 or len(y_pred) < 2:\n",
    "        return np.nan\n",
    "    try:\n",
    "        return float(np.corrcoef(y_true, y_pred)[0,1])\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def fit_nonlinear_series(x, y, model_name):\n",
    "    def f_quad(z, a, b, c): return a*z**2 + b*z + c\n",
    "    def f_exp(z, a, b, c):  return a*np.exp(b*z) + c\n",
    "    def f_inv(z, a, b):     return a + b/np.where(z==0, np.finfo(float).eps, z)\n",
    "\n",
    "    if model_name == \"Cuadrática\":\n",
    "        popt, _ = curve_fit(f_quad, x, y, maxfev=20000)\n",
    "        yhat = f_quad(x, *popt)\n",
    "        return yhat, popt\n",
    "    elif model_name == \"Exponencial\":\n",
    "        p0 = (1.0, 0.01, float(np.nanmedian(y)))\n",
    "        popt, _ = curve_fit(f_exp, x, y, p0=p0, maxfev=20000)\n",
    "        yhat = f_exp(x, *popt)\n",
    "        return yhat, popt\n",
    "    else:  # Inversa\n",
    "        popt, _ = curve_fit(f_inv, x, y, maxfev=20000)\n",
    "        yhat = f_inv(x, *popt)\n",
    "        return yhat, popt\n",
    "\n",
    "def coerce_numeric_cols(df, cols):\n",
    "    \"\"\"Devuelve una copia donde 'cols' se convierten a numérico con errors='coerce'.\"\"\"\n",
    "    d = df.copy()\n",
    "    for c in cols:\n",
    "        if c in d.columns:\n",
    "            d[c] = pd.to_numeric(d[c], errors='coerce')\n",
    "    return d\n",
    "\n",
    "# =========================\n",
    "# Configuración app\n",
    "# =========================\n",
    "st.set_page_config(\n",
    "    page_title=\"Dashboard Mult-ciudad Airbnb: Proyecto Innovativo Grupo IPYNB\",\n",
    "    page_icon=\"🏠\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "# --- Portada (Imagen + Título + Descripción) ---\n",
    "# Ruta proporcionada por el usuario (cámbiala si tu archivo está en otra ubicación)\n",
    "PORTADA_PATHS = [\n",
    "    \"WhatsApp Image 2025-10-22 at 11.38.03 PM.jpeg\",\n",
    "    \"./assets/aura.jpg\",\n",
    "    \"./assets/aura.png\",\n",
    "    \"/mnt/data/WhatsApp Image 2025-10-22 at 11.38.03 PM.jpeg\",\n",
    "]\n",
    "img_path = next((p for p in PORTADA_PATHS if os.path.exists(p)), None)\n",
    "if img_path:\n",
    "    col_l, col_c, col_r = st.columns([1,2,1])\n",
    "    with col_c:\n",
    "        st.image(img_path, use_column_width=True)\n",
    "else:\n",
    "    st.info(\"⚠️ Imagen de portada no encontrada. Verifica la ruta en PORTADA_PATHS.\")\n",
    "\n",
    "st.title(\"Dashboard Mult-ciudad Airbnb: Proyecto Innovativo Grupo IPYNB\")\n",
    "st.write(\"**Este dashboard permite establecer un panorama completo de Airbnb, sus Hosts y Alojamientos, potencializando al Programa AURA.**\")\n",
    "\n",
    "# =========================\n",
    "# Sidebar\n",
    "# =========================\n",
    "with st.sidebar:\n",
    "    st.header(\"⚙️ Configuración\")\n",
    "    color = st.color_picker(\"Color principal\", \"#0B6E4F\")\n",
    "    grid_alpha = st.slider(\"Transparencia de rejilla\", 0.0, 1.0, 0.2, 0.05)\n",
    "    st.markdown(\"---\")\n",
    "    st.subheader(\"📂 Carga de datos (opcional)\")\n",
    "    ups = st.file_uploader(\"Sube CSV (puedes múltiples)\", type=[\"csv\"], accept_multiple_files=True)\n",
    "\n",
    "# =========================\n",
    "# Carga de datasets base\n",
    "# =========================\n",
    "df_mex = unify_schema(safe_read_csv(\"Mexico_Limpio.csv\"), \"Mexico\")\n",
    "df_mad = unify_schema(safe_read_csv(\"Madrid_AirBnb_010.csv\"), \"Madrid\")\n",
    "df_val = unify_schema(safe_read_csv(\"VALENCIA_LIMPIO.csv\"), \"Valencia\")\n",
    "df_rio = unify_schema(safe_read_csv(\"base_final.csv\"), \"Rio\")   # <- etiqueta \"Rio\"\n",
    "df_roma = unify_schema(safe_read_csv(\"df_limp_ROMA.csv\"), \"Roma\")\n",
    "\n",
    "dfs_raw = [d for d in [df_mex, df_mad, df_val, df_rio, df_roma] if d is not None]\n",
    "\n",
    "if ups:\n",
    "    for f in ups:\n",
    "        try:\n",
    "            tmp = pd.read_csv(f)\n",
    "            dfs_raw.append(unify_schema(tmp, city_name=os.path.splitext(f.name)[0]))\n",
    "        except Exception as e:\n",
    "            st.warning(f\"No se pudo leer {f.name}: {e}\")\n",
    "\n",
    "if not dfs_raw:\n",
    "    st.error(\"No se encontraron datos. Coloca los CSV en la carpeta o súbelos.\")\n",
    "    st.stop()\n",
    "\n",
    "# Intersección de columnas comunes para asegurar comparabilidad\n",
    "common_cols = set(dfs_raw[0].columns)\n",
    "for d in dfs_raw[1:]:\n",
    "    common_cols = common_cols.intersection(set(d.columns))\n",
    "common_cols = sorted(list(common_cols))\n",
    "\n",
    "# Reindexa cada DF a columnas comunes\n",
    "dfs = [d[common_cols].copy() for d in dfs_raw]\n",
    "\n",
    "# Concat para análisis global\n",
    "df_all = pd.concat(dfs, ignore_index=True)\n",
    "cities_all = sorted(df_all[\"city\"].dropna().astype(str).unique().tolist())\n",
    "\n",
    "# Selección de ciudades a comparar\n",
    "sel_cities = st.multiselect(\"🌍 Ciudades a comparar\", options=cities_all, default=cities_all)\n",
    "if not sel_cities:\n",
    "    st.warning(\"Selecciona al menos una ciudad.\")\n",
    "    st.stop()\n",
    "df = df_all[df_all[\"city\"].isin(sel_cities)].reset_index(drop=True)\n",
    "\n",
    "# Columnas por tipo (en universo común)\n",
    "num_cols_all = [c for c in common_cols if pd.api.types.is_numeric_dtype(df[c])]\n",
    "cat_cols_all = [c for c in common_cols if (df[c].dtype == \"object\" or str(df[c].dtype).startswith(\"category\"))]\n",
    "\n",
    "# =========================\n",
    "# Tabs (7 secciones)\n",
    "# =========================\n",
    "tabs = st.tabs([\n",
    "    \"1) 🧰 Extracción\",\n",
    "    \"2) 🔠 Categóricas\",\n",
    "    \"3) 📈 Regresión Lineal Simple\",\n",
    "    \"4) 🧮 Regresión Lineal Múltiple\",\n",
    "    \"5) 🌀 Regresión No Lineal\",\n",
    "    \"6) 🧪 Regresión Logística\",\n",
    "    \"7) 💡 Insights & Propuestas\",\n",
    "])\n",
    "\n",
    "# ============================================================\n",
    "# TAB 1 - Extracción (comparativos de variables de servicio)\n",
    "# ============================================================\n",
    "with tabs[0]:\n",
    "    st.subheader(\"🧰 Extracción: comparativo de variables clave por ciudad\")\n",
    "    st.caption(\"Variables típicas: price, number_of_reviews, availability_365, calculated_host_listings_count, accommodates, reviews_per_month, minimum_nights, estimated_occupancy_l365d, review_scores_rating.\")\n",
    "\n",
    "    candidates = [\n",
    "        \"price\", \"number_of_reviews\", \"availability_365\",\n",
    "        \"calculated_host_listings_count\", \"host_total_listings_count\",\n",
    "        \"accommodates\", \"reviews_per_month\", \"minimum_nights\",\n",
    "        \"estimated_occupancy_l365d\", \"review_scores_rating\"\n",
    "    ]\n",
    "    present = [c for c in candidates if c in common_cols]\n",
    "    sel_vars = st.multiselect(\"Variables a comparar\", options=present, default=present)\n",
    "\n",
    "    if not sel_vars:\n",
    "        st.info(\"Selecciona al menos una variable.\")\n",
    "    else:\n",
    "        # Conversión segura a numérico\n",
    "        df_num = coerce_numeric_cols(df, sel_vars)\n",
    "\n",
    "        # KPIs por ciudad (mediana y promedio)\n",
    "        try:\n",
    "            kpi = (df_num.groupby(\"city\")[sel_vars]\n",
    "                   .agg(['median', 'mean'])\n",
    "                   .round(3))\n",
    "            st.dataframe(kpi, use_container_width=True)\n",
    "        except Exception as e:\n",
    "            st.warning(f\"No fue posible calcular median/mean: {e}\")\n",
    "\n",
    "        # Gráficas por variable (box + barras) con columnas numéricas\n",
    "        for v in sel_vars:\n",
    "            st.markdown(f\"**Variable:** `{v}`\")\n",
    "            c1, c2 = st.columns(2)\n",
    "\n",
    "            with c1:\n",
    "                try:\n",
    "                    fig = px.box(df_num, x=\"city\", y=v, points=\"outliers\", color=\"city\",\n",
    "                                 title=f\"Distribución de {v} por ciudad\")\n",
    "                    st.plotly_chart(fig, use_container_width=True)\n",
    "                except Exception:\n",
    "                    st.info(f\"No se pudo graficar boxplot para {v}.\")\n",
    "\n",
    "            with c2:\n",
    "                try:\n",
    "                    # SeriesGroupBy.median sin numeric_only (ya es numérico)\n",
    "                    agg = df_num.groupby(\"city\")[v].median().reset_index()\n",
    "                    fig2 = px.bar(agg, x=\"city\", y=v, title=f\"Mediana de {v} por ciudad\")\n",
    "                    st.plotly_chart(fig2, use_container_width=True)\n",
    "                except Exception:\n",
    "                    st.info(f\"No se pudo graficar barras para {v}.\")\n",
    "\n",
    "# ============================================================\n",
    "# TAB 2 - Categóricas (10 comunes)\n",
    "# ============================================================\n",
    "with tabs[1]:\n",
    "    st.subheader(\"🔠 Análisis de variables categóricas (reglas específicas)\")\n",
    "    st.caption(\"room_type y host_is_superhost en todas; neighbourhood y host_response_time solo donde existan (no en México).\")\n",
    "\n",
    "    # --- Variables canónicas a usar ---\n",
    "    canonical = [\"room_type\", \"host_is_superhost\", \"neighbourhood\", \"host_response_time\"]\n",
    "\n",
    "    # Aliases para ubicar columnas equivalentes por nombre\n",
    "    alias_map = {\n",
    "        \"room_type\": [\"room_type\", \"room\", \"tipo_habitacion\"],\n",
    "        \"host_is_superhost\": [\"host_is_superhost\", \"is_superhost\", \"superhost\"],\n",
    "        \"neighbourhood\": [\"neighbourhood\", \"neighborhood\", \"neighbourhood_cleansed\", \"barrio\", \"district\", \"zona\"],\n",
    "        \"host_response_time\": [\"host_response_time\", \"response_time\", \"tiempo_respuesta\"],\n",
    "    }\n",
    "\n",
    "    def find_col(df_local, aliases):\n",
    "        cols = list(df_local.columns)\n",
    "        low_cols = [c.lower() for c in cols]\n",
    "        # Exacta (case-insensitive)\n",
    "        for a in aliases:\n",
    "            if a.lower() in low_cols:\n",
    "                return cols[low_cols.index(a.lower())]\n",
    "        # Inclusión parcial\n",
    "        for a in aliases:\n",
    "            for i, c in enumerate(low_cols):\n",
    "                if a.lower() in c:\n",
    "                    return cols[i]\n",
    "        return None\n",
    "\n",
    "    def to_yes_no(series):\n",
    "        s = series.astype(str).str.lower().str.strip()\n",
    "        yes = {\"1\",\"t\",\"true\",\"yes\",\"si\",\"sí\",\"y\",\"s\"}\n",
    "        no  = {\"0\",\"f\",\"false\",\"no\",\"n\"}\n",
    "        return np.where(s.isin(yes), \"Sí\",\n",
    "                        np.where(s.isin(no), \"No\", series.astype(str)))\n",
    "\n",
    "    # --- Construcción del DataFrame categórico unificado ---\n",
    "    cat_frames = []\n",
    "    mapping_rows = []\n",
    "\n",
    "    for d in dfs_raw:\n",
    "        if d is None or \"city\" not in d.columns or d.empty:\n",
    "            continue\n",
    "\n",
    "        tmp = pd.DataFrame()\n",
    "        tmp[\"city\"] = d[\"city\"].astype(str)\n",
    "\n",
    "        # Detecta si el DF es de México (para excluir neighbourhood/response_time)\n",
    "        df_has_mexico = tmp[\"city\"].astype(str).str.lower().str.contains(\"mexico\").any()\n",
    "\n",
    "        # 1. room_type → siempre\n",
    "        src_room = find_col(d, alias_map[\"room_type\"])\n",
    "        tmp[\"room_type\"] = d[src_room] if src_room else np.nan\n",
    "\n",
    "        # 2. host_is_superhost → siempre (convertido a Sí/No)\n",
    "        src_super = find_col(d, alias_map[\"host_is_superhost\"])\n",
    "        if src_super:\n",
    "            tmp[\"host_is_superhost\"] = pd.Series(to_yes_no(d[src_super])).astype(\"category\")\n",
    "        else:\n",
    "            tmp[\"host_is_superhost\"] = np.nan\n",
    "\n",
    "        # 3. neighbourhood → solo donde exista y no sea México\n",
    "        src_neigh = find_col(d, alias_map[\"neighbourhood\"])\n",
    "        if (not df_has_mexico) and src_neigh:\n",
    "            tmp[\"neighbourhood\"] = d[src_neigh]\n",
    "        else:\n",
    "            tmp[\"neighbourhood\"] = np.nan\n",
    "\n",
    "        # 4. host_response_time → solo donde exista y no sea México\n",
    "        src_resp = find_col(d, alias_map[\"host_response_time\"])\n",
    "        if (not df_has_mexico) and src_resp:\n",
    "            tmp[\"host_response_time\"] = d[src_resp]\n",
    "        else:\n",
    "            tmp[\"host_response_time\"] = np.nan\n",
    "\n",
    "        cat_frames.append(tmp)\n",
    "\n",
    "        # Para mostrar en la tabla qué columnas se usaron\n",
    "        cities_str = \", \".join(sorted(tmp[\"city\"].astype(str).unique().tolist()))\n",
    "        mapping_rows.append({\n",
    "            \"Ciudad(es) en DF\": cities_str,\n",
    "            \"room_type <-\": src_room if src_room else \"❌\",\n",
    "            \"host_is_superhost <-\": src_super if src_super else \"❌\",\n",
    "            \"neighbourhood <-\": (src_neigh if (src_neigh and not df_has_mexico) else \"❌ (descartado o no existe)\"),\n",
    "            \"host_response_time <-\": (src_resp if (src_resp and not df_has_mexico) else \"❌ (descartado o no existe)\"),\n",
    "        })\n",
    "\n",
    "    if not cat_frames:\n",
    "        st.warning(\"No se pudieron construir variables categóricas desde los datasets originales.\")\n",
    "        st.stop()\n",
    "\n",
    "    df_cat_all = pd.concat(cat_frames, ignore_index=True)\n",
    "    df_cat = df_cat_all[df_cat_all[\"city\"].isin(sel_cities)].copy()\n",
    "\n",
    "    if df_cat.empty:\n",
    "        st.warning(\"No hay registros categóricos en las ciudades seleccionadas.\")\n",
    "        st.stop()\n",
    "\n",
    "    # Mostrar mapeo de columnas detectadas por dataset/ciudad\n",
    "    with st.expander(\"Ver mapeo de columnas utilizadas por dataset/ciudad\"):\n",
    "        st.dataframe(pd.DataFrame(mapping_rows), use_container_width=True)\n",
    "\n",
    "    # Filtra solo las variables realmente disponibles con datos\n",
    "    present_cats = [c for c in canonical if c in df_cat.columns and df_cat[c].notna().any()]\n",
    "\n",
    "    # Selector para activar/desactivar variables\n",
    "    sel_cats = st.multiselect(\n",
    "        \"Selecciona variables a visualizar\",\n",
    "        options=present_cats,\n",
    "        default=present_cats,\n",
    "        max_selections=len(present_cats)\n",
    "    )\n",
    "\n",
    "    if not sel_cats:\n",
    "        st.info(\"Selecciona al menos una variable categórica.\")\n",
    "    else:\n",
    "        for cat in sel_cats:\n",
    "            st.markdown(f\"### 📊 Variable: `{cat}`\")\n",
    "\n",
    "            # --- Distribución global ---\n",
    "            try:\n",
    "                dist = df_cat[cat].astype(\"category\").value_counts(dropna=False).reset_index()\n",
    "                dist.columns = [cat, \"Frecuencia\"]\n",
    "\n",
    "                col1, col2 = st.columns(2)\n",
    "                with col1:\n",
    "                    fig_bar = px.bar(\n",
    "                        dist, x=cat, y=\"Frecuencia\", color=cat,\n",
    "                        title=f\"Frecuencia global de {cat}\"\n",
    "                    )\n",
    "                    st.plotly_chart(fig_bar, use_container_width=True)\n",
    "\n",
    "                with col2:\n",
    "                    fig_pie = px.pie(\n",
    "                        dist, names=cat, values=\"Frecuencia\",\n",
    "                        title=f\"Participación global de {cat}\"\n",
    "                    )\n",
    "                    st.plotly_chart(fig_pie, use_container_width=True)\n",
    "\n",
    "            except Exception as e:\n",
    "                st.warning(f\"No se pudo graficar {cat}: {e}\")\n",
    "\n",
    "            # --- Comparativo por ciudad ---\n",
    "            try:\n",
    "                cross = (\n",
    "                    df_cat.groupby([\"city\", cat])\n",
    "                          .size()\n",
    "                          .reset_index(name=\"Conteo\")\n",
    "                )\n",
    "                fig_cross = px.bar(\n",
    "                    cross, x=\"city\", y=\"Conteo\", color=cat,\n",
    "                    barmode=\"group\", title=f\"{cat} por ciudad\"\n",
    "                )\n",
    "                st.plotly_chart(fig_cross, use_container_width=True)\n",
    "            except Exception as e:\n",
    "                st.warning(f\"No se pudo generar el comparativo de {cat} por ciudad: {e}\")\n",
    "\n",
    "        st.success(\"✅ Tab 2 configurado según reglas: room_type y superhost en todas; neighbourhood y response_time solo donde existan (no México).\")\n",
    "\n",
    "# ============================================================\n",
    "# TAB 3 - Regresión Lineal Simple (por ciudad)\n",
    "# ============================================================\n",
    "with tabs[2]:\n",
    "    st.subheader(\"📈 Regresión Lineal Simple (comparativa por ciudad)\")\n",
    "    if len(num_cols_all) < 2:\n",
    "        st.info(\"Se requieren al menos dos variables numéricas comunes.\")\n",
    "    else:\n",
    "        col1, col2 = st.columns(2)\n",
    "        with col1:\n",
    "            y_lin = st.selectbox(\"Y (numérica)\", options=num_cols_all, key=\"lin_y\")\n",
    "        with col2:\n",
    "            x_lin = st.selectbox(\"X (numérica)\", options=[c for c in num_cols_all if c != y_lin], key=\"lin_x\")\n",
    "\n",
    "        sel_c_lin = st.multiselect(\"Ciudades a incluir\", options=sel_cities, default=sel_cities, key=\"lin_cities\")\n",
    "        results = []\n",
    "        for city in sel_c_lin:\n",
    "            dfx = df[df[\"city\"]==city][[x_lin, y_lin]].copy()\n",
    "            dfx[x_lin] = pd.to_numeric(dfx[x_lin], errors='coerce')\n",
    "            dfx[y_lin] = pd.to_numeric(dfx[y_lin], errors='coerce')\n",
    "            dfx = dfx.dropna()\n",
    "            if len(dfx) < 8:\n",
    "                results.append({\"city\": city, \"R2\": np.nan, \"R\": np.nan, \"n\": len(dfx)})\n",
    "                st.info(f\"{city}: datos insuficientes.\")\n",
    "                continue\n",
    "            X = dfx[[x_lin]].values\n",
    "            Y = dfx[y_lin].values\n",
    "            Xtr, Xte, Ytr, Yte = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "            model = LinearRegression().fit(Xtr, Ytr)\n",
    "            yhat = model.predict(Xte)\n",
    "            R2 = r2_score(Yte, yhat)\n",
    "            R = r_from_y_ypred(Yte, yhat)\n",
    "            results.append({\"city\": city, \"R2\": R2, \"R\": R, \"n\": len(dfx)})\n",
    "\n",
    "            # Gráfico por ciudad\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.scatter(X, Y, alpha=0.5)\n",
    "            X_sorted = np.sort(X, axis=0)\n",
    "            ax.plot(X_sorted, model.predict(X_sorted), color=color, lw=2)\n",
    "            ax.set_title(f\"{city} | {y_lin} ~ {x_lin}\")\n",
    "            ax.set_xlabel(x_lin); ax.set_ylabel(y_lin); ax.grid(alpha=grid_alpha)\n",
    "            st.pyplot(fig, use_container_width=True)\n",
    "\n",
    "        st.markdown(\"**Resumen de métricas (test):**\")\n",
    "        st.dataframe(pd.DataFrame(results).round(3), use_container_width=True)\n",
    "\n",
    "# ============================================================\n",
    "# TAB 4 - Regresión Lineal Múltiple (por ciudad)\n",
    "# ============================================================\n",
    "with tabs[3]:\n",
    "    st.subheader(\"🧮 Regresión Lineal Múltiple (comparativa por ciudad)\")\n",
    "    if len(num_cols_all) < 3:\n",
    "        st.info(\"Se requieren ≥ 3 variables numéricas comunes para múltiple.\")\n",
    "    else:\n",
    "        col1, col2 = st.columns([1,2])\n",
    "        with col1:\n",
    "            y_mul = st.selectbox(\"Y (numérica)\", options=num_cols_all, key=\"mul_y\")\n",
    "        with col2:\n",
    "            x_mul = st.multiselect(\"X (numéricas)\", options=[c for c in num_cols_all if c != y_mul],\n",
    "                                   default=[c for c in num_cols_all if c != y_mul][:3], key=\"mul_x\")\n",
    "        if not x_mul:\n",
    "            st.info(\"Selecciona al menos una X.\")\n",
    "        else:\n",
    "            sel_c_mul = st.multiselect(\"Ciudades a incluir\", options=sel_cities, default=sel_cities, key=\"mul_cities\")\n",
    "            rows = []\n",
    "            for city in sel_c_mul:\n",
    "                cols = [y_mul] + x_mul\n",
    "                dfx = df[df[\"city\"]==city][cols].copy()\n",
    "                for c in cols:\n",
    "                    dfx[c] = pd.to_numeric(dfx[c], errors='coerce')\n",
    "                dfx = dfx.dropna()\n",
    "                if len(dfx) < 10:\n",
    "                    rows.append({\"city\": city, \"R2\": np.nan, \"R\": np.nan, \"n\": len(dfx)})\n",
    "                    st.info(f\"{city}: datos insuficientes.\")\n",
    "                    continue\n",
    "                X = dfx[x_mul].values\n",
    "                Y = dfx[y_mul].values\n",
    "                Xtr, Xte, Ytr, Yte = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "                model = LinearRegression().fit(Xtr, Ytr)\n",
    "                yhat = model.predict(Xte)\n",
    "                R2 = r2_score(Yte, yhat)\n",
    "                R = r_from_y_ypred(Yte, yhat)\n",
    "                rows.append({\"city\": city, \"R2\": R2, \"R\": R, \"n\": len(dfx)})\n",
    "\n",
    "                # Gráfico real vs predicho\n",
    "                fig, ax = plt.subplots()\n",
    "                ax.scatter(Yte, yhat, alpha=0.6)\n",
    "                m = [min(Yte.min(), yhat.min()), max(Yte.max(), yhat.max())]\n",
    "                ax.plot(m, m, '--', lw=1)\n",
    "                ax.set_title(f\"{city} | {y_mul} ~ {', '.join(x_mul)}\")\n",
    "                ax.set_xlabel(\"Real\"); ax.set_ylabel(\"Predicho\"); ax.grid(alpha=grid_alpha)\n",
    "                st.pyplot(fig, use_container_width=True)\n",
    "\n",
    "            st.markdown(\"**Resumen de métricas (test):**\")\n",
    "            st.dataframe(pd.DataFrame(rows).round(3), use_container_width=True)\n",
    "\n",
    "# ============================================================\n",
    "# TAB 5 - Regresión No Lineal (por ciudad)\n",
    "# ============================================================\n",
    "with tabs[4]:\n",
    "    st.subheader(\"🌀 Regresión No Lineal (comparativa por ciudad)\")\n",
    "    if len(num_cols_all) < 2:\n",
    "        st.info(\"Se requieren al menos dos variables numéricas comunes.\")\n",
    "    else:\n",
    "        c1, c2, c3 = st.columns(3)\n",
    "        with c1:\n",
    "            y_nl = st.selectbox(\"Y\", options=num_cols_all, key=\"nl_y\")\n",
    "        with c2:\n",
    "            x_nl = st.selectbox(\"X\", options=[c for c in num_cols_all if c != y_nl], key=\"nl_x\")\n",
    "        with c3:\n",
    "            model_nl = st.selectbox(\"Modelo\", [\"Cuadrática\", \"Exponencial\", \"Inversa\"], index=0)\n",
    "\n",
    "        sel_c_nl = st.multiselect(\"Ciudades a incluir\", options=sel_cities, default=sel_cities, key=\"nl_cities\")\n",
    "        rows = []\n",
    "        for city in sel_c_nl:\n",
    "            dfx = df[df[\"city\"]==city][[x_nl, y_nl]].copy()\n",
    "            dfx[x_nl] = pd.to_numeric(dfx[x_nl], errors='coerce')\n",
    "            dfx[y_nl] = pd.to_numeric(dfx[y_nl], errors='coerce')\n",
    "            dfx = dfx.dropna().sort_values(x_nl)\n",
    "            if len(dfx) < 10:\n",
    "                rows.append({\"city\": city, \"R2\": np.nan, \"R\": np.nan, \"n\": len(dfx)})\n",
    "                st.info(f\"{city}: datos insuficientes.\")\n",
    "                continue\n",
    "            x = dfx[x_nl].astype(float).values\n",
    "            y = dfx[y_nl].astype(float).values\n",
    "            try:\n",
    "                yhat, popt = fit_nonlinear_series(x, y, model_nl)\n",
    "                R2 = r2_score(y, yhat)\n",
    "                R = r_from_y_ypred(y, yhat)\n",
    "                rows.append({\"city\": city, \"R2\": R2, \"R\": R, \"n\": len(dfx)})\n",
    "\n",
    "                # Gráfico\n",
    "                fig, ax = plt.subplots()\n",
    "                ax.scatter(x, y, alpha=0.5)\n",
    "                ax.plot(x, yhat, color=color, lw=2)\n",
    "                ax.set_title(f\"{city} | {y_nl} ~ {x_nl} ({model_nl})\")\n",
    "                ax.set_xlabel(x_nl); ax.set_ylabel(y_nl); ax.grid(alpha=grid_alpha)\n",
    "                st.pyplot(fig, use_container_width=True)\n",
    "            except Exception as e:\n",
    "                rows.append({\"city\": city, \"R2\": np.nan, \"R\": np.nan, \"n\": len(dfx)})\n",
    "                st.warning(f\"{city}: fallo del ajuste ({e}).\")\n",
    "\n",
    "        st.markdown(\"**Resumen de métricas (ajuste in-sample):**\")\n",
    "        st.dataframe(pd.DataFrame(rows).round(3), use_container_width=True)\n",
    "\n",
    "# ============================================================\n",
    "# TAB 6 - Regresión Logística (por ciudad)\n",
    "# ============================================================\n",
    "with tabs[5]:\n",
    "    st.subheader(\"🧪 Regresión Logística (comparativa por ciudad)\")\n",
    "    cols_all = list(common_cols)\n",
    "    y_choice = st.selectbox(\"Variable dependiente (Y)\", options=cols_all, key=\"log_y\")\n",
    "    x_choices = st.multiselect(\"Variables explicativas (X)\", options=[c for c in cols_all if c != y_choice], max_selections=6, key=\"log_xs\")\n",
    "\n",
    "    if not x_choices:\n",
    "        st.info(\"Selecciona al menos una X.\")\n",
    "    else:\n",
    "        dfY = df[y_choice]\n",
    "        # --- Binarización Y (SOLO Media o Manual) ---\n",
    "        st.markdown(\"**Binarización de Y**\")\n",
    "        if pd.api.types.is_numeric_dtype(dfY):\n",
    "            howY = st.selectbox(\"Método (Y numérica)\", [\"Media\", \"Manual\"], index=0, key=\"y_thr_m\")\n",
    "            if howY == \"Media\":\n",
    "                thrY = float(dfY.dropna().mean())\n",
    "            else:\n",
    "                thrY = st.number_input(\"Umbral manual Y\", value=float(dfY.dropna().mean()), key=\"y_thr_i\")\n",
    "            y_bin = (dfY >= thrY).astype(int)\n",
    "            st.caption(f\"Y binaria: 1 si {y_choice} ≥ {thrY:.4f}\")\n",
    "        else:\n",
    "            uniq = dfY.dropna().astype(str).unique().tolist()\n",
    "            pos = st.selectbox(\"Clase positiva (Y=1)\", options=sorted(uniq), key=\"y_pos\")\n",
    "            y_bin = (dfY.astype(str) == pos).astype(int)\n",
    "            st.caption(f\"Y binaria: 1 si {y_choice} == '{pos}'\")\n",
    "\n",
    "        # --- Binarización opcional de UNA X numérica (SOLO Media o Manual) ---\n",
    "        st.markdown(\"**Binarización opcional de X (una X numérica específica)**\")\n",
    "        binarize_x = st.checkbox(\"Binarizar una X numérica\", value=False, key=\"bx_flag\")\n",
    "        X_design = df[x_choices].copy()\n",
    "        if binarize_x:\n",
    "            x_num_candidates = [c for c in x_choices if pd.api.types.is_numeric_dtype(df[c])]\n",
    "            if x_num_candidates:\n",
    "                x_bin_name = st.selectbox(\"X a binarizar\", options=x_num_candidates, key=\"bx_sel\")\n",
    "                howX = st.selectbox(\"Método (X numérica)\", [\"Media\", \"Manual\"], index=0, key=\"x_thr_m\")\n",
    "                if howX == \"Media\":\n",
    "                    x_bin_thr = float(df[x_bin_name].dropna().mean())\n",
    "                else:\n",
    "                    x_bin_thr = st.number_input(\"Umbral manual X\", value=float(df[x_bin_name].dropna().mean()), key=\"x_thr_i\")\n",
    "                X_design[x_bin_name] = (df[x_bin_name] >= x_bin_thr).astype(int)\n",
    "                st.caption(f\"{x_bin_name} binaria: 1 si ≥ {x_bin_thr:.4f}\")\n",
    "            else:\n",
    "                st.info(\"No hay X numéricas seleccionadas para binarizar.\")\n",
    "\n",
    "        # --- class_weight & split ---\n",
    "        use_bal = st.checkbox(\"Usar class_weight='balanced'\", value=True, key=\"cw\")\n",
    "        test_size = st.slider(\"Proporción de test\", 0.1, 0.5, 0.3, 0.05, key=\"tsz\")\n",
    "\n",
    "        sel_c_log = st.multiselect(\"Ciudades a incluir\", options=sel_cities, default=sel_cities, key=\"log_cities\")\n",
    "        rows = []\n",
    "        for city in sel_c_log:\n",
    "            dfx = X_design[df[\"city\"]==city].copy()\n",
    "            yy = y_bin[df[\"city\"]==city].copy()\n",
    "            # Conversión numérica de X por seguridad\n",
    "            for c in dfx.columns:\n",
    "                dfx[c] = pd.to_numeric(dfx[c], errors='coerce')\n",
    "            data = pd.concat([dfx, yy.rename(\"__y\")], axis=1).dropna()\n",
    "            if data[\"__y\"].nunique() < 2 or len(data) < 30:\n",
    "                rows.append({\"city\": city, \"AUC\": np.nan, \"Precision\": np.nan, \"Recall\": np.nan, \"F1\": np.nan, \"n\": len(data)})\n",
    "                st.info(f\"{city}: datos insuficientes o una sola clase.\")\n",
    "                continue\n",
    "\n",
    "            X = data.drop(columns=\"__y\").values\n",
    "            y = data[\"__y\"].astype(int).values\n",
    "\n",
    "            Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=test_size, random_state=42, stratify=y)\n",
    "            pipe = Pipeline([\n",
    "                (\"scaler\", StandardScaler(with_mean=True, with_std=True)),\n",
    "                (\"logit\", LogisticRegression(max_iter=600, class_weight=(\"balanced\" if use_bal else None)))\n",
    "            ])\n",
    "            pipe.fit(Xtr, ytr)\n",
    "            proba = pipe.predict_proba(Xte)[:,1]\n",
    "            pred = (proba >= 0.5).astype(int)\n",
    "\n",
    "            AUC = roc_auc_score(yte, proba)\n",
    "            PREC = precision_score(yte, pred, zero_division=0)\n",
    "            REC = recall_score(yte, pred, zero_division=0)\n",
    "            F1 = f1_score(yte, pred, zero_division=0)\n",
    "            rows.append({\"city\": city, \"AUC\": AUC, \"Precision\": PREC, \"Recall\": REC, \"F1\": F1, \"n\": len(data)})\n",
    "\n",
    "            # Gráfico ROC por ciudad\n",
    "            fpr, tpr, thr = roc_curve(yte, proba)\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(fpr, tpr, lw=2, label=f\"AUC={AUC:.3f}\")\n",
    "            ax.plot([0,1],[0,1],'--', lw=1)\n",
    "            ax.set_title(f\"ROC - {city}\")\n",
    "            ax.set_xlabel(\"FPR\"); ax.set_ylabel(\"TPR\"); ax.legend(); ax.grid(alpha=grid_alpha)\n",
    "            st.pyplot(fig, use_container_width=True)\n",
    "\n",
    "        st.markdown(\"**Resumen de métricas (test):**\")\n",
    "        st.dataframe(pd.DataFrame(rows).round(3), use_container_width=True)\n",
    "\n",
    "# ============================================================\n",
    "# TAB 7 - Insights & Propuestas\n",
    "# ============================================================\n",
    "with tabs[6]:\n",
    "    st.subheader(\"📊 Insights y Recomendaciones Estratégicas\")\n",
    "    st.caption(\"Comparación de medias entre ciudades usando variables reconstruidas desde los datasets originales (sin intersección). Incluye % de Superhosts (T).\")\n",
    "\n",
    "    import re, unicodedata\n",
    "\n",
    "    # ---- Utilidades robustas ----\n",
    "    def _norm_txt(s: str) -> str:\n",
    "        s = str(s)\n",
    "        s = unicodedata.normalize(\"NFKD\", s)\n",
    "        s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
    "        return s.strip().lower()\n",
    "\n",
    "    def is_mex(name: str) -> bool:\n",
    "        n = _norm_txt(name)\n",
    "        return bool(\n",
    "            re.search(r\"^mex\", n) or\n",
    "            re.search(r\"ciudad\\s*de\\s*mex\", n) or\n",
    "            re.search(r\"\\bcdmx\\b\", n) or\n",
    "            re.fullmatch(r\"mx\", n)\n",
    "        )\n",
    "\n",
    "    def find_col(df_local, aliases):\n",
    "        cols = list(df_local.columns)\n",
    "        low = [c.strip().lower() for c in cols]\n",
    "        # exacta\n",
    "        for a in aliases:\n",
    "            a2 = a.strip().lower()\n",
    "            if a2 in low:\n",
    "                return cols[low.index(a2)]\n",
    "        # inclusión parcial\n",
    "        for a in aliases:\n",
    "            a2 = a.strip().lower()\n",
    "            for i, c in enumerate(low):\n",
    "                if a2 in c:\n",
    "                    return cols[i]\n",
    "        return None\n",
    "\n",
    "    def clean_numeric_like(series):\n",
    "        s = series.astype(str).str.replace(r\"[^\\d,.\\-]\", \"\", regex=True)\n",
    "        mask_coma_decimal = ~s.str.contains(r\"\\.\") & s.str.contains(\",\")\n",
    "        s.loc[mask_coma_decimal] = s.loc[mask_coma_decimal].str.replace(\",\", \".\", regex=False)\n",
    "        s = s.str.replace(\",\", \"\", regex=False)\n",
    "        return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "    # ---- Aliases por variable ----\n",
    "    alias = {\n",
    "        \"host_is_superhost\": [\"host_is_superhost\", \"is_superhost\", \"superhost\"],\n",
    "        \"host_response_time\": [\"host_response_time\", \"response_time\", \"tiempo_respuesta\"],\n",
    "        \"calculated_host_listings_count\": [\"calculated_host_listings_count\", \"host_total_listings_count\"],\n",
    "        \"price\": [\"price\", \"precio\"],\n",
    "        \"number_of_reviews\": [\"number_of_reviews\", \"reviews\"],\n",
    "        \"availability_365\": [\"availability_365\"],\n",
    "    }\n",
    "\n",
    "    # ---- Reconstrucción desde dfs_raw ----\n",
    "    recs = []       # filas unificadas\n",
    "    mappings = []   # mapeo por dataset\n",
    "\n",
    "    for d in dfs_raw:\n",
    "        if d is None or d.empty or \"city\" not in d.columns:\n",
    "            continue\n",
    "        df_local = d.copy()\n",
    "        df_local.columns = [str(c).strip() for c in df_local.columns]\n",
    "\n",
    "        tmp = pd.DataFrame()\n",
    "        tmp[\"city\"] = df_local[\"city\"].astype(str)\n",
    "\n",
    "        # host_is_superhost (con regla para México)\n",
    "        col_hsh = find_col(df_local, alias[\"host_is_superhost\"])\n",
    "        if col_hsh:\n",
    "            raw = df_local[col_hsh].astype(str).str.strip().str.lower()\n",
    "            # máscara México\n",
    "            mex_mask = tmp[\"city\"].map(is_mex).fillna(False)\n",
    "\n",
    "            # México: SOLO T/F/1/0 -> map estricta; resto NaN\n",
    "            map_mex = {\"t\": 1, \"f\": 0, \"1\": 1, \"0\": 0}\n",
    "            tmp.loc[mex_mask, \"host_is_superhost_num\"] = raw[mex_mask].map(map_mex)\n",
    "\n",
    "            # Otras ciudades: mapeo flexible clásico\n",
    "            oth = ~mex_mask\n",
    "            tmp.loc[oth, \"host_is_superhost_num\"] = np.where(\n",
    "                raw[oth].isin([\"t\",\"true\",\"1\",\"yes\",\"si\",\"sí\",\"y\",\"s\"]), 1,\n",
    "                np.where(raw[oth].isin([\"f\",\"false\",\"0\",\"no\",\"n\"]), 0, np.nan)\n",
    "            )\n",
    "\n",
    "            # También versión F/T para diagnóstico y visual\n",
    "            tmp[\"host_is_superhost_str\"] = tmp[\"host_is_superhost_num\"].map({1.0: \"T\", 0.0: \"F\"})\n",
    "        else:\n",
    "            tmp[\"host_is_superhost_num\"] = np.nan\n",
    "            tmp[\"host_is_superhost_str\"] = np.nan\n",
    "\n",
    "        # host_response_time -> ordinal 4..1\n",
    "        col_rt = find_col(df_local, alias[\"host_response_time\"])\n",
    "        if col_rt:\n",
    "            m = {\n",
    "                \"within an hour\": 4, \"within a few hours\": 3,\n",
    "                \"within a day\": 2, \"a few days or more\": 1\n",
    "            }\n",
    "            tmp[\"host_response_time\"] = (\n",
    "                df_local[col_rt].astype(str).str.strip().str.lower().map(m)\n",
    "            )\n",
    "        else:\n",
    "            tmp[\"host_response_time\"] = np.nan\n",
    "\n",
    "        # calculated_host_listings_count\n",
    "        col_chl = find_col(df_local, alias[\"calculated_host_listings_count\"])\n",
    "        if col_chl:\n",
    "            tmp[\"calculated_host_listings_count\"] = pd.to_numeric(df_local[col_chl], errors=\"coerce\")\n",
    "        else:\n",
    "            tmp[\"calculated_host_listings_count\"] = np.nan\n",
    "\n",
    "        # price (limpieza general; NaN se ignoran en medias; caso Valencia ya cubierto)\n",
    "        col_price = find_col(df_local, alias[\"price\"])\n",
    "        if col_price:\n",
    "            tmp[\"price\"] = clean_numeric_like(df_local[col_price])\n",
    "        else:\n",
    "            tmp[\"price\"] = np.nan\n",
    "\n",
    "        # number_of_reviews\n",
    "        col_nor = find_col(df_local, alias[\"number_of_reviews\"])\n",
    "        if col_nor:\n",
    "            tmp[\"number_of_reviews\"] = pd.to_numeric(df_local[col_nor], errors=\"coerce\")\n",
    "        else:\n",
    "            tmp[\"number_of_reviews\"] = np.nan\n",
    "\n",
    "        # availability_365\n",
    "        col_av = find_col(df_local, alias[\"availability_365\"])\n",
    "        if col_av:\n",
    "            tmp[\"availability_365\"] = pd.to_numeric(df_local[col_av], errors=\"coerce\")\n",
    "        else:\n",
    "            tmp[\"availability_365\"] = np.nan\n",
    "\n",
    "        recs.append(tmp)\n",
    "\n",
    "        # mapeo informativo\n",
    "        maps = {\n",
    "            \"Ciudad(es) en DF\": \", \".join(sorted(tmp[\"city\"].astype(str).unique())),\n",
    "            \"host_is_superhost <-\": col_hsh if col_hsh else \"❌\",\n",
    "            \"host_response_time <-\": col_rt if col_rt else \"❌\",\n",
    "            \"calculated_host_listings_count <-\": col_chl if col_chl else \"❌\",\n",
    "            \"price <-\": col_price if col_price else \"❌\",\n",
    "            \"number_of_reviews <-\": col_nor if col_nor else \"❌\",\n",
    "            \"availability_365 <-\": col_av if col_av else \"❌\",\n",
    "        }\n",
    "        mappings.append(maps)\n",
    "\n",
    "    if not recs:\n",
    "        st.warning(\"No hay datos disponibles para generar insights.\")\n",
    "        st.stop()\n",
    "\n",
    "    df_ins = pd.concat(recs, ignore_index=True)\n",
    "    # Filtra por las ciudades seleccionadas\n",
    "    df_ins = df_ins[df_ins[\"city\"].isin(sel_cities)].copy()\n",
    "\n",
    "    # ---- Diagnóstico de mapeos ----\n",
    "    with st.expander(\"🔎 Mapeo de columnas utilizadas por dataset\"):\n",
    "        st.dataframe(pd.DataFrame(mappings), use_container_width=True)\n",
    "\n",
    "    # ---- Tabla de diagnóstico Superhosts F/T por ciudad ----\n",
    "    with st.expander(\"🔍 Distribución F/T por ciudad (host_is_superhost)\"):\n",
    "        if \"host_is_superhost_str\" in df_ins.columns:\n",
    "            diag = (\n",
    "                df_ins.groupby([\"city\", \"host_is_superhost_str\"])\n",
    "                .size()\n",
    "                .unstack(fill_value=0)\n",
    "                .rename(columns={\"F\": \"F (No)\", \"T\": \"T (Sí)\"})\n",
    "            )\n",
    "            st.dataframe(diag, use_container_width=True)\n",
    "\n",
    "    # ---- Cálculo de medias por ciudad ----\n",
    "    metrics = [\"host_is_superhost_num\", \"host_response_time\",\n",
    "               \"calculated_host_listings_count\", \"price\",\n",
    "               \"number_of_reviews\", \"availability_365\"]\n",
    "\n",
    "    summary = {}\n",
    "    for v in metrics:\n",
    "        if v in df_ins.columns:\n",
    "            df_ins[v] = pd.to_numeric(df_ins[v], errors=\"coerce\")\n",
    "            mean_v = df_ins.groupby(\"city\")[v].mean().round(2)\n",
    "            if mean_v.notna().any():\n",
    "                summary[v] = mean_v\n",
    "\n",
    "    if not summary:\n",
    "        st.warning(\"No fue posible calcular medias (todas las series vacías).\")\n",
    "        st.stop()\n",
    "\n",
    "    df_summary = pd.DataFrame(summary).sort_index()\n",
    "\n",
    "    # Porcentaje de Superhosts (T) por ciudad\n",
    "    if \"host_is_superhost_num\" in df_summary.columns:\n",
    "        df_summary[\"%_superhosts\"] = (df_summary[\"host_is_superhost_num\"] * 100).round(1)\n",
    "\n",
    "    st.markdown(\"### 📈 Comparativo de medias entre ciudades\")\n",
    "    st.dataframe(df_summary, use_container_width=True)\n",
    "\n",
    "    # ---- Gráficas ----\n",
    "    # Hosts\n",
    "    st.markdown(\"#### 🧑‍💼 Métricas de Hosts\")\n",
    "    for v, title in [\n",
    "        (\"host_is_superhost_num\", \"% Superhosts (promedio 0/1)\"),\n",
    "        (\"host_response_time\", \"Rapidez de respuesta (4=mejor)\"),\n",
    "        (\"calculated_host_listings_count\", \"Propiedades por host (promedio)\"),\n",
    "    ]:\n",
    "        if v in df_summary.columns:\n",
    "            fig = px.bar(df_summary.reset_index(), x=\"city\", y=v, color=\"city\",\n",
    "                         title=f\"{title} — promedio por ciudad\")\n",
    "            st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    # Hospedaje\n",
    "    st.markdown(\"#### 🏠 Métricas de Hospedaje\")\n",
    "    for v, title in [\n",
    "        (\"price\", \"Precio promedio\"),\n",
    "        (\"number_of_reviews\", \"Reseñas promedio\"),\n",
    "        (\"availability_365\", \"Disponibilidad promedio (días)\"),\n",
    "    ]:\n",
    "        if v in df_summary.columns:\n",
    "            fig = px.bar(df_summary.reset_index(), x=\"city\", y=v, color=\"city\",\n",
    "                         title=f\"{title} — promedio por ciudad\")\n",
    "            st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    # ---- Insights ----\n",
    "    st.markdown(\"### 💡 Principales Insights\")\n",
    "    insights = []\n",
    "\n",
    "    # % de Superhosts por ciudad (texto explícito)\n",
    "    if \"%_superhosts\" in df_summary.columns:\n",
    "        for city, pct in df_summary[\"%_superhosts\"].items():\n",
    "            insights.append(f\"En **{city}**, el **{pct:.1f}%** de los anfitriones son Superhosts (T).\")\n",
    "\n",
    "    def top_city(col, desc, maximize=True):\n",
    "        if col in df_summary.columns and df_summary[col].notna().any():\n",
    "            idx = df_summary[col].idxmax() if maximize else df_summary[col].idxmin()\n",
    "            val = df_summary.loc[idx, col]\n",
    "            return f\"**{idx}** {'lidera' if maximize else 'presenta el menor valor'} en **{desc}** ({val:.2f}).\"\n",
    "        return None\n",
    "\n",
    "    t = top_city(\"host_response_time\", \"rapidez de respuesta de anfitriones\")\n",
    "    if t: insights.append(t)\n",
    "    t = top_city(\"calculated_host_listings_count\", \"promedio de propiedades por host\")\n",
    "    if t: insights.append(t)\n",
    "    t = top_city(\"price\", \"precio promedio\")\n",
    "    if t: insights.append(t)\n",
    "    t = top_city(\"number_of_reviews\", \"reseñas promedio por alojamiento\")\n",
    "    if t: insights.append(t)\n",
    "    t = top_city(\"availability_365\", \"disponibilidad promedio anual\")\n",
    "    if t: insights.append(t)\n",
    "\n",
    "    if insights:\n",
    "        for ins in insights:\n",
    "            st.markdown(f\"✅ {ins}\")\n",
    "    else:\n",
    "        st.info(\"No se generaron insights automáticos (verifica variables disponibles).\")\n",
    "\n",
    "    # ---- Recomendaciones ----\n",
    "    st.markdown(\"### 🧭 Recomendaciones Estratégicas\")\n",
    "    recs = []\n",
    "    if \"%_superhosts\" in df_summary.columns:\n",
    "        minc = df_summary[\"%_superhosts\"].idxmin()\n",
    "        recs.append(f\"- **{minc}**: impulsar la ruta a Superhost (mentoría + checklist de amenities) para elevar el % de superhosts.\")\n",
    "    if \"host_response_time\" in df_summary.columns:\n",
    "        minr = df_summary[\"host_response_time\"].idxmin()\n",
    "        recs.append(f\"- **{minr}**: activar respuestas automáticas y recordatorios para mejorar tiempos de respuesta de hosts.\")\n",
    "    if \"availability_365\" in df_summary.columns:\n",
    "        maxa = df_summary[\"availability_365\"].idxmax()\n",
    "        recs.append(f\"- **{maxa}**: aplicar pricing dinámico y promos de temporada baja para reducir vacancia anual.\")\n",
    "    if \"price\" in df_summary.columns:\n",
    "        maxp = df_summary[\"price\"].idxmax()\n",
    "        recs.append(f\"- **{maxp}**: consolidar oferta premium y low-budget (bundles: late checkout, limpieza) como estrategia comercial.\")\n",
    "    if \"number_of_reviews\" in df_summary.columns:\n",
    "        minrv = df_summary[\"number_of_reviews\"].idxmin()\n",
    "        recs.append(f\"- **{minrv}**: campañas de visibilidad + recordatorios post-estancia para aumentar reseñas.\")\n",
    "    if \"calculated_host_listings_count\" in df_summary.columns:\n",
    "        maxh = df_summary[\"calculated_host_listings_count\"].idxmax()\n",
    "        recs.append(f\"- **{maxh}**: estrategia de diversificación de alojamientos.\")\n",
    "\n",
    "    for r in recs:\n",
    "        st.markdown(r)\n",
    "\n",
    "    st.success(\"✅ host_is_superhost de MÉXICO tomado correctamente (solo T/F/1/0) y % de T por ciudad calculado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
