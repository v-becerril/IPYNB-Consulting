{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "038d22d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.50.0)\n",
      "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (6.2.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (8.3.0)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (2.3.4)\n",
      "Requirement already satisfied: packaging<26,>=20 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from streamlit) (25.0)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (2.3.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (11.3.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (6.33.0)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (21.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (2.32.5)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (4.15.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (3.1.45)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from streamlit) (6.5.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.8.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from seaborn) (2.3.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from seaborn) (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: plotly in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (6.3.1)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from plotly) (2.8.0)\n",
      "Requirement already satisfied: packaging in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from plotly) (25.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: statsmodels in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.14.5)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from statsmodels) (2.3.4)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from statsmodels) (1.16.2)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from statsmodels) (2.3.3)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from statsmodels) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[1G\u001b[0K‚†ô\u001b[1G\u001b[0K‚†π\u001b[1G\u001b[0K‚†∏\u001b[1G\u001b[0K‚†º\u001b[1G\u001b[0K‚†¥\u001b[1G\u001b[0K‚†¶\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K\n",
      "up to date, audited 23 packages in 897ms\n",
      "\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K\n",
      "\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K3 packages are looking for funding\n",
      "\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K  run `npm fund` for details\n",
      "\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K\n",
      "2 \u001b[31m\u001b[1mhigh\u001b[22m\u001b[39m severity vulnerabilities\n",
      "\n",
      "To address all issues (including breaking changes), run:\n",
      "  npm audit fix --force\n",
      "\n",
      "Run `npm audit` for details.\n",
      "\u001b[1G\u001b[0K‚†ß\u001b[1G\u001b[0K"
     ]
    }
   ],
   "source": [
    "%pip install streamlit\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install scikit-learn\n",
    "%pip install plotly\n",
    "%pip install statsmodels\n",
    "\n",
    "#Para instalar npm en visual studio\n",
    "#1.Desde Google escribir node.js\n",
    "#2. Instalar la versi√≥n m√°s recomendada\n",
    "! npm install localtunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5e50a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting EVIDENCIA_2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile EVIDENCIA_2.py\n",
    "\n",
    "## streamlit run EVIDENCIA_2.py\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    r2_score, mean_absolute_error, mean_squared_error,\n",
    "    precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, roc_curve\n",
    ")\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# =========================\n",
    "# Utilidades base\n",
    "# =========================\n",
    "def safe_read_csv(path):\n",
    "    try:\n",
    "        if os.path.exists(path):\n",
    "            return pd.read_csv(path)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def unify_schema(df, city_name=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Normaliza nombres, resuelve columnas duplicadas, agrega 'city',\n",
    "    y convierte strings con '%' a num√©ricos. Evita AttributeError.\n",
    "    \"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        return None\n",
    "\n",
    "    # 1) Normaliza nombres a snake_case\n",
    "    cols_raw = list(df.columns)\n",
    "    norm_cols = [str(c).strip().lower().replace(\" \", \"_\") for c in cols_raw]\n",
    "\n",
    "    # 2) Unifica duplicados: col, col__1, col__2, ...\n",
    "    seen = {}\n",
    "    unique_cols = []\n",
    "    dups = []\n",
    "    for c in norm_cols:\n",
    "        if c not in seen:\n",
    "            seen[c] = 0\n",
    "            unique_cols.append(c)\n",
    "        else:\n",
    "            seen[c] += 1\n",
    "            new_c = f\"{c}__{seen[c]}\"\n",
    "            unique_cols.append(new_c)\n",
    "            dups.append((c, new_c))\n",
    "    if verbose and dups:\n",
    "        print(\"Columnas duplicadas renombradas:\", dups)\n",
    "\n",
    "    df = df.copy()\n",
    "    df.columns = unique_cols\n",
    "\n",
    "    # 3) Correcciones habituales\n",
    "    ren = {\n",
    "        \"accomodates\": \"accommodates\",\n",
    "        \"bedroms\": \"bedrooms\",\n",
    "        \"bathroom\": \"bathrooms\",\n",
    "        \"host_response_time(%)\": \"host_response_rate\",\n",
    "        \"review_scores_value\": \"review_scores_rating\"\n",
    "    }\n",
    "    for k, v in ren.items():\n",
    "        if k in df.columns and v not in df.columns:\n",
    "            df.rename(columns={k: v}, inplace=True)\n",
    "\n",
    "    # 4) Asegura 'city'\n",
    "    if \"city\" not in df.columns:\n",
    "        df[\"city\"] = city_name if city_name else \"unknown\"\n",
    "    else:\n",
    "        if city_name:\n",
    "            df[\"city\"] = df[\"city\"].fillna(city_name).replace(\"\", city_name)\n",
    "\n",
    "    # 5) Convierte columnas con s√≠mbolo %\n",
    "    for c in df.columns:\n",
    "        s = df[c]\n",
    "        if pd.api.types.is_object_dtype(s):\n",
    "            if s.astype(str).str.contains(\"%\").any():\n",
    "                s2 = s.astype(str).str.replace(\"%\", \"\", regex=False)\n",
    "                s2 = pd.to_numeric(s2, errors=\"coerce\")\n",
    "                df[c] = s2\n",
    "\n",
    "    return df\n",
    "\n",
    "def numeric_cols(df):\n",
    "    return [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "def categorical_cols(df):\n",
    "    return [c for c in df.columns if (df[c].dtype == \"object\" or str(df[c].dtype).startswith(\"category\"))]\n",
    "\n",
    "def r_from_y_ypred(y_true, y_pred):\n",
    "    if len(y_true) < 2 or len(y_pred) < 2:\n",
    "        return np.nan\n",
    "    try:\n",
    "        return float(np.corrcoef(y_true, y_pred)[0,1])\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def fit_nonlinear_series(x, y, model_name):\n",
    "    def f_quad(z, a, b, c): return a*z**2 + b*z + c\n",
    "    def f_exp(z, a, b, c):  return a*np.exp(b*z) + c\n",
    "    def f_inv(z, a, b):     return a + b/np.where(z==0, np.finfo(float).eps, z)\n",
    "\n",
    "    if model_name == \"Cuadr√°tica\":\n",
    "        popt, _ = curve_fit(f_quad, x, y, maxfev=20000)\n",
    "        yhat = f_quad(x, *popt)\n",
    "        return yhat, popt\n",
    "    elif model_name == \"Exponencial\":\n",
    "        p0 = (1.0, 0.01, float(np.nanmedian(y)))\n",
    "        popt, _ = curve_fit(f_exp, x, y, p0=p0, maxfev=20000)\n",
    "        yhat = f_exp(x, *popt)\n",
    "        return yhat, popt\n",
    "    else:  # Inversa\n",
    "        popt, _ = curve_fit(f_inv, x, y, maxfev=20000)\n",
    "        yhat = f_inv(x, *popt)\n",
    "        return yhat, popt\n",
    "\n",
    "def coerce_numeric_cols(df, cols):\n",
    "    \"\"\"Devuelve una copia donde 'cols' se convierten a num√©rico con errors='coerce'.\"\"\"\n",
    "    d = df.copy()\n",
    "    for c in cols:\n",
    "        if c in d.columns:\n",
    "            d[c] = pd.to_numeric(d[c], errors='coerce')\n",
    "    return d\n",
    "\n",
    "# =========================\n",
    "# Configuraci√≥n app\n",
    "# =========================\n",
    "st.set_page_config(\n",
    "    page_title=\"Dashboard Mult-ciudad Airbnb: Proyecto Innovativo Grupo IPYNB\",\n",
    "    page_icon=\"üè†\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "# --- Portada (Imagen + T√≠tulo + Descripci√≥n) ---\n",
    "# Ruta proporcionada por el usuario (c√°mbiala si tu archivo est√° en otra ubicaci√≥n)\n",
    "PORTADA_PATHS = [\n",
    "    \"WhatsApp Image 2025-10-22 at 11.38.03 PM.jpeg\",\n",
    "    \"./assets/aura.jpg\",\n",
    "    \"./assets/aura.png\",\n",
    "    \"/mnt/data/WhatsApp Image 2025-10-22 at 11.38.03 PM.jpeg\",\n",
    "]\n",
    "img_path = next((p for p in PORTADA_PATHS if os.path.exists(p)), None)\n",
    "if img_path:\n",
    "    col_l, col_c, col_r = st.columns([1,2,1])\n",
    "    with col_c:\n",
    "        st.image(img_path, use_column_width=True)\n",
    "else:\n",
    "    st.info(\"‚ö†Ô∏è Imagen de portada no encontrada. Verifica la ruta en PORTADA_PATHS.\")\n",
    "\n",
    "st.title(\"Dashboard Mult-ciudad Airbnb: Proyecto Innovativo Grupo IPYNB\")\n",
    "st.write(\"**Este dashboard permite establecer un panorama completo de Airbnb, sus Hosts y Alojamientos, potencializando al Programa AURA.**\")\n",
    "\n",
    "# =========================\n",
    "# Sidebar\n",
    "# =========================\n",
    "with st.sidebar:\n",
    "    st.header(\"‚öôÔ∏è Configuraci√≥n\")\n",
    "    color = st.color_picker(\"Color principal\", \"#0B6E4F\")\n",
    "    grid_alpha = st.slider(\"Transparencia de rejilla\", 0.0, 1.0, 0.2, 0.05)\n",
    "    st.markdown(\"---\")\n",
    "    st.subheader(\"üìÇ Carga de datos (opcional)\")\n",
    "    ups = st.file_uploader(\"Sube CSV (puedes m√∫ltiples)\", type=[\"csv\"], accept_multiple_files=True)\n",
    "\n",
    "# =========================\n",
    "# Carga de datasets base\n",
    "# =========================\n",
    "df_mex = unify_schema(safe_read_csv(\"Mexico_Limpio_modified.csv\"), \"Mexico\")\n",
    "df_mad = unify_schema(safe_read_csv(\"Madrid_AirBnb_010.csv\"), \"Madrid\")\n",
    "df_val = unify_schema(safe_read_csv(\"VALENCIA_LIMPIO.csv\"), \"Valencia\")\n",
    "df_rio = unify_schema(safe_read_csv(\"base_final.csv\"), \"Rio\")   # <- etiqueta \"Rio\"\n",
    "df_roma = unify_schema(safe_read_csv(\"df_limp_ROMA.csv\"), \"Roma\")\n",
    "\n",
    "dfs_raw = [d for d in [df_mex, df_mad, df_val, df_rio, df_roma] if d is not None]\n",
    "\n",
    "if ups:\n",
    "    for f in ups:\n",
    "        try:\n",
    "            tmp = pd.read_csv(f)\n",
    "            dfs_raw.append(unify_schema(tmp, city_name=os.path.splitext(f.name)[0]))\n",
    "        except Exception as e:\n",
    "            st.warning(f\"No se pudo leer {f.name}: {e}\")\n",
    "\n",
    "if not dfs_raw:\n",
    "    st.error(\"No se encontraron datos. Coloca los CSV en la carpeta o s√∫belos.\")\n",
    "    st.stop()\n",
    "\n",
    "# Intersecci√≥n de columnas comunes para asegurar comparabilidad\n",
    "common_cols = set(dfs_raw[0].columns)\n",
    "for d in dfs_raw[1:]:\n",
    "    common_cols = common_cols.intersection(set(d.columns))\n",
    "common_cols = sorted(list(common_cols))\n",
    "\n",
    "# Reindexa cada DF a columnas comunes\n",
    "dfs = [d[common_cols].copy() for d in dfs_raw]\n",
    "\n",
    "# Concat para an√°lisis global\n",
    "df_all = pd.concat(dfs, ignore_index=True)\n",
    "cities_all = sorted(df_all[\"city\"].dropna().astype(str).unique().tolist())\n",
    "\n",
    "# Selecci√≥n de ciudades a comparar\n",
    "sel_cities = st.multiselect(\"üåç Ciudades a comparar\", options=cities_all, default=cities_all)\n",
    "if not sel_cities:\n",
    "    st.warning(\"Selecciona al menos una ciudad.\")\n",
    "    st.stop()\n",
    "df = df_all[df_all[\"city\"].isin(sel_cities)].reset_index(drop=True)\n",
    "\n",
    "# Columnas por tipo (en universo com√∫n)\n",
    "num_cols_all = [c for c in common_cols if pd.api.types.is_numeric_dtype(df[c])]\n",
    "cat_cols_all = [c for c in common_cols if (df[c].dtype == \"object\" or str(df[c].dtype).startswith(\"category\"))]\n",
    "\n",
    "# =========================\n",
    "# Tabs (7 secciones)\n",
    "# =========================\n",
    "tabs = st.tabs([\n",
    "    \"1) üß∞ Extracci√≥n\",\n",
    "    \"2) üî† Categ√≥ricas\",\n",
    "    \"3) üìà Regresi√≥n Lineal Simple\",\n",
    "    \"4) üßÆ Regresi√≥n Lineal M√∫ltiple\",\n",
    "    \"5) üåÄ Regresi√≥n No Lineal\",\n",
    "    \"6) üß™ Regresi√≥n Log√≠stica\",\n",
    "    \"7) üí° Insights & Propuestas\",\n",
    "])\n",
    "\n",
    "# ============================================================\n",
    "# TAB 1 - Extracci√≥n (comparativos de variables de servicio)\n",
    "# ============================================================\n",
    "with tabs[0]:\n",
    "    st.subheader(\"üß∞ Extracci√≥n: comparativo de variables clave por ciudad\")\n",
    "    st.caption(\"Variables t√≠picas: price, number_of_reviews, availability_365, calculated_host_listings_count, accommodates, reviews_per_month, minimum_nights, estimated_occupancy_l365d, review_scores_rating.\")\n",
    "\n",
    "    candidates = [\n",
    "        \"price\", \"number_of_reviews\", \"availability_365\",\n",
    "        \"calculated_host_listings_count\", \"host_total_listings_count\",\n",
    "        \"accommodates\", \"reviews_per_month\", \"minimum_nights\",\n",
    "        \"estimated_occupancy_l365d\", \"review_scores_rating\"\n",
    "    ]\n",
    "    present = [c for c in candidates if c in common_cols]\n",
    "    sel_vars = st.multiselect(\"Variables a comparar\", options=present, default=present)\n",
    "\n",
    "    if not sel_vars:\n",
    "        st.info(\"Selecciona al menos una variable.\")\n",
    "    else:\n",
    "        # Conversi√≥n segura a num√©rico\n",
    "        df_num = coerce_numeric_cols(df, sel_vars)\n",
    "\n",
    "        # KPIs por ciudad (mediana y promedio)\n",
    "        try:\n",
    "            kpi = (df_num.groupby(\"city\")[sel_vars]\n",
    "                   .agg(['median', 'mean'])\n",
    "                   .round(3))\n",
    "            st.dataframe(kpi, use_container_width=True)\n",
    "        except Exception as e:\n",
    "            st.warning(f\"No fue posible calcular median/mean: {e}\")\n",
    "\n",
    "        # Gr√°ficas por variable (box + barras) con columnas num√©ricas\n",
    "        for v in sel_vars:\n",
    "            st.markdown(f\"**Variable:** `{v}`\")\n",
    "            c1, c2 = st.columns(2)\n",
    "\n",
    "            with c1:\n",
    "                try:\n",
    "                    fig = px.box(df_num, x=\"city\", y=v, points=\"outliers\", color=\"city\",\n",
    "                                 title=f\"Distribuci√≥n de {v} por ciudad\")\n",
    "                    st.plotly_chart(fig, use_container_width=True)\n",
    "                except Exception:\n",
    "                    st.info(f\"No se pudo graficar boxplot para {v}.\")\n",
    "\n",
    "            with c2:\n",
    "                try:\n",
    "                    # SeriesGroupBy.median sin numeric_only (ya es num√©rico)\n",
    "                    agg = df_num.groupby(\"city\")[v].median().reset_index()\n",
    "                    fig2 = px.bar(agg, x=\"city\", y=v, title=f\"Mediana de {v} por ciudad\")\n",
    "                    st.plotly_chart(fig2, use_container_width=True)\n",
    "                except Exception:\n",
    "                    st.info(f\"No se pudo graficar barras para {v}.\")\n",
    "\n",
    "# ============================================================\n",
    "# TAB 2 - Categ√≥ricas (10 comunes)\n",
    "# ============================================================\n",
    "with tabs[1]:\n",
    "    st.subheader(\"üî† An√°lisis de variables categ√≥ricas (reglas espec√≠ficas)\")\n",
    "    st.caption(\"room_type y host_is_superhost en todas; neighbourhood y host_response_time solo donde existan (no en M√©xico).\")\n",
    "\n",
    "    # --- Variables can√≥nicas a usar ---\n",
    "    canonical = [\"room_type\", \"host_is_superhost\", \"neighbourhood\", \"host_response_time\"]\n",
    "\n",
    "    # Aliases para ubicar columnas equivalentes por nombre\n",
    "    alias_map = {\n",
    "        \"room_type\": [\"room_type\", \"room\", \"tipo_habitacion\"],\n",
    "        \"host_is_superhost\": [\"host_is_superhost\", \"is_superhost\", \"superhost\"],\n",
    "        \"neighbourhood\": [\"neighbourhood\", \"neighborhood\", \"neighbourhood_cleansed\", \"barrio\", \"district\", \"zona\"],\n",
    "        \"host_response_time\": [\"host_response_time\", \"response_time\", \"tiempo_respuesta\"],\n",
    "    }\n",
    "\n",
    "    def find_col(df_local, aliases):\n",
    "        cols = list(df_local.columns)\n",
    "        low_cols = [c.lower() for c in cols]\n",
    "        # Exacta (case-insensitive)\n",
    "        for a in aliases:\n",
    "            if a.lower() in low_cols:\n",
    "                return cols[low_cols.index(a.lower())]\n",
    "        # Inclusi√≥n parcial\n",
    "        for a in aliases:\n",
    "            for i, c in enumerate(low_cols):\n",
    "                if a.lower() in c:\n",
    "                    return cols[i]\n",
    "        return None\n",
    "\n",
    "    def to_yes_no(series):\n",
    "        s = series.astype(str).str.lower().str.strip()\n",
    "        yes = {\"1\",\"t\",\"true\",\"yes\",\"si\",\"s√≠\",\"y\",\"s\"}\n",
    "        no  = {\"0\",\"f\",\"false\",\"no\",\"n\"}\n",
    "        return np.where(s.isin(yes), \"S√≠\",\n",
    "                        np.where(s.isin(no), \"No\", series.astype(str)))\n",
    "\n",
    "    # --- Construcci√≥n del DataFrame categ√≥rico unificado ---\n",
    "    cat_frames = []\n",
    "    mapping_rows = []\n",
    "\n",
    "    for d in dfs_raw:\n",
    "        if d is None or \"city\" not in d.columns or d.empty:\n",
    "            continue\n",
    "\n",
    "        tmp = pd.DataFrame()\n",
    "        tmp[\"city\"] = d[\"city\"].astype(str)\n",
    "\n",
    "        # Detecta si el DF es de M√©xico (para excluir neighbourhood/response_time)\n",
    "        df_has_mexico = tmp[\"city\"].astype(str).str.lower().str.contains(\"mexico\").any()\n",
    "\n",
    "        # 1. room_type ‚Üí siempre\n",
    "        src_room = find_col(d, alias_map[\"room_type\"])\n",
    "        tmp[\"room_type\"] = d[src_room] if src_room else np.nan\n",
    "\n",
    "        # 2. host_is_superhost ‚Üí siempre (convertido a S√≠/No)\n",
    "        src_super = find_col(d, alias_map[\"host_is_superhost\"])\n",
    "        if src_super:\n",
    "            tmp[\"host_is_superhost\"] = pd.Series(to_yes_no(d[src_super])).astype(\"category\")\n",
    "        else:\n",
    "            tmp[\"host_is_superhost\"] = np.nan\n",
    "\n",
    "        # 3. neighbourhood ‚Üí solo donde exista y no sea M√©xico\n",
    "        src_neigh = find_col(d, alias_map[\"neighbourhood\"])\n",
    "        if (not df_has_mexico) and src_neigh:\n",
    "            tmp[\"neighbourhood\"] = d[src_neigh]\n",
    "        else:\n",
    "            tmp[\"neighbourhood\"] = np.nan\n",
    "\n",
    "        # 4. host_response_time ‚Üí solo donde exista y no sea M√©xico\n",
    "        src_resp = find_col(d, alias_map[\"host_response_time\"])\n",
    "        if (not df_has_mexico) and src_resp:\n",
    "            tmp[\"host_response_time\"] = d[src_resp]\n",
    "        else:\n",
    "            tmp[\"host_response_time\"] = np.nan\n",
    "\n",
    "        cat_frames.append(tmp)\n",
    "\n",
    "        # Para mostrar en la tabla qu√© columnas se usaron\n",
    "        cities_str = \", \".join(sorted(tmp[\"city\"].astype(str).unique().tolist()))\n",
    "        mapping_rows.append({\n",
    "            \"Ciudad(es) en DF\": cities_str,\n",
    "            \"room_type <-\": src_room if src_room else \"‚ùå\",\n",
    "            \"host_is_superhost <-\": src_super if src_super else \"‚ùå\",\n",
    "            \"neighbourhood <-\": (src_neigh if (src_neigh and not df_has_mexico) else \"‚ùå (descartado o no existe)\"),\n",
    "            \"host_response_time <-\": (src_resp if (src_resp and not df_has_mexico) else \"‚ùå (descartado o no existe)\"),\n",
    "        })\n",
    "\n",
    "    if not cat_frames:\n",
    "        st.warning(\"No se pudieron construir variables categ√≥ricas desde los datasets originales.\")\n",
    "        st.stop()\n",
    "\n",
    "    df_cat_all = pd.concat(cat_frames, ignore_index=True)\n",
    "    df_cat = df_cat_all[df_cat_all[\"city\"].isin(sel_cities)].copy()\n",
    "\n",
    "    if df_cat.empty:\n",
    "        st.warning(\"No hay registros categ√≥ricos en las ciudades seleccionadas.\")\n",
    "        st.stop()\n",
    "\n",
    "    # Mostrar mapeo de columnas detectadas por dataset/ciudad\n",
    "    with st.expander(\"Ver mapeo de columnas utilizadas por dataset/ciudad\"):\n",
    "        st.dataframe(pd.DataFrame(mapping_rows), use_container_width=True)\n",
    "\n",
    "    # Filtra solo las variables realmente disponibles con datos\n",
    "    present_cats = [c for c in canonical if c in df_cat.columns and df_cat[c].notna().any()]\n",
    "\n",
    "    # Selector para activar/desactivar variables\n",
    "    sel_cats = st.multiselect(\n",
    "        \"Selecciona variables a visualizar\",\n",
    "        options=present_cats,\n",
    "        default=present_cats,\n",
    "        max_selections=len(present_cats)\n",
    "    )\n",
    "\n",
    "    if not sel_cats:\n",
    "        st.info(\"Selecciona al menos una variable categ√≥rica.\")\n",
    "    else:\n",
    "        for cat in sel_cats:\n",
    "            st.markdown(f\"### üìä Variable: `{cat}`\")\n",
    "\n",
    "            # --- Distribuci√≥n global ---\n",
    "            try:\n",
    "                dist = df_cat[cat].astype(\"category\").value_counts(dropna=False).reset_index()\n",
    "                dist.columns = [cat, \"Frecuencia\"]\n",
    "\n",
    "                col1, col2 = st.columns(2)\n",
    "                with col1:\n",
    "                    fig_bar = px.bar(\n",
    "                        dist, x=cat, y=\"Frecuencia\", color=cat,\n",
    "                        title=f\"Frecuencia global de {cat}\"\n",
    "                    )\n",
    "                    st.plotly_chart(fig_bar, use_container_width=True)\n",
    "\n",
    "                with col2:\n",
    "                    fig_pie = px.pie(\n",
    "                        dist, names=cat, values=\"Frecuencia\",\n",
    "                        title=f\"Participaci√≥n global de {cat}\"\n",
    "                    )\n",
    "                    st.plotly_chart(fig_pie, use_container_width=True)\n",
    "\n",
    "            except Exception as e:\n",
    "                st.warning(f\"No se pudo graficar {cat}: {e}\")\n",
    "\n",
    "            # --- Comparativo por ciudad ---\n",
    "            try:\n",
    "                cross = (\n",
    "                    df_cat.groupby([\"city\", cat])\n",
    "                          .size()\n",
    "                          .reset_index(name=\"Conteo\")\n",
    "                )\n",
    "                fig_cross = px.bar(\n",
    "                    cross, x=\"city\", y=\"Conteo\", color=cat,\n",
    "                    barmode=\"group\", title=f\"{cat} por ciudad\"\n",
    "                )\n",
    "                st.plotly_chart(fig_cross, use_container_width=True)\n",
    "            except Exception as e:\n",
    "                st.warning(f\"No se pudo generar el comparativo de {cat} por ciudad: {e}\")\n",
    "\n",
    "        st.success(\"‚úÖ Tab 2 configurado seg√∫n reglas: room_type y superhost en todas; neighbourhood y response_time solo donde existan (no M√©xico).\")\n",
    "\n",
    "# ============================================================\n",
    "# TAB 3 - Regresi√≥n Lineal Simple (facet por ciudad, Plotly ampliado)\n",
    "# ============================================================\n",
    "with tabs[2]:\n",
    "    st.subheader(\"üìê Regresi√≥n Lineal Simple (comparativo multi-ciudad)\")\n",
    "    st.caption(\"Selecciona X e Y; se muestran todas las ciudades en facetas, con l√≠nea de ajuste y m√©tricas R¬≤ y R.\")\n",
    "\n",
    "    # Ciudades\n",
    "    try:\n",
    "        cities_sel = sel_cities\n",
    "    except NameError:\n",
    "        cities_sel = sorted(df_all[\"city\"].dropna().unique().tolist())\n",
    "\n",
    "    # Definici√≥n segura de X e Y\n",
    "    if \"x_var\" not in locals() or \"y_var\" not in locals():\n",
    "        num_cols_all = df_all.select_dtypes(include=[\"int\", \"float\", \"Int64\", \"Float64\"]).columns.tolist()\n",
    "        fallback_numeric = [\"price\", \"number_of_reviews\", \"availability_365\", \"reviews_per_month\",\n",
    "                            \"calculated_host_listings_count\", \"host_total_listings_count\"]\n",
    "        for col in fallback_numeric:\n",
    "            if col in df_all.columns and col not in num_cols_all:\n",
    "                df_all[col] = pd.to_numeric(df_all[col], errors=\"coerce\")\n",
    "        num_cols_all = df_all.select_dtypes(include=[\"int\", \"float\", \"Int64\", \"Float64\"]).columns.tolist()\n",
    "        x_default = \"availability_365\" if \"availability_365\" in num_cols_all else (num_cols_all[0] if num_cols_all else None)\n",
    "        y_default = \"price\" if \"price\" in num_cols_all else (num_cols_all[1] if len(num_cols_all) > 1 else None)\n",
    "        x_var, y_var = x_default, y_default\n",
    "\n",
    "    num_cols_ui = df_all.select_dtypes(include=[\"int\", \"float\", \"Int64\", \"Float64\"]).columns.tolist()\n",
    "    if not num_cols_ui:\n",
    "        st.warning(\"No se detectaron columnas num√©ricas para realizar la regresi√≥n.\")\n",
    "        st.stop()\n",
    "\n",
    "    x_var = st.selectbox(\"Variable X (independiente)\", options=num_cols_ui,\n",
    "                         index=max(0, num_cols_ui.index(x_var) if x_var in num_cols_ui else 0),\n",
    "                         key=\"tab3_x_var\")\n",
    "    y_var = st.selectbox(\"Variable Y (dependiente)\", options=num_cols_ui,\n",
    "                         index=max(0, num_cols_ui.index(y_var) if y_var in num_cols_ui else (1 if len(num_cols_ui)>1 else 0)),\n",
    "                         key=\"tab3_y_var\")\n",
    "\n",
    "    if x_var == y_var:\n",
    "        st.info(\"Selecciona variables distintas para X e Y.\")\n",
    "        st.stop()\n",
    "\n",
    "    # Datos\n",
    "    data_lin = df_all[df_all[\"city\"].isin(cities_sel)][[\"city\", x_var, y_var]].copy()\n",
    "    data_lin[x_var] = pd.to_numeric(data_lin[x_var], errors=\"coerce\")\n",
    "    data_lin[y_var] = pd.to_numeric(data_lin[y_var], errors=\"coerce\")\n",
    "    data_lin = data_lin.dropna(subset=[x_var, y_var])\n",
    "    if data_lin.empty:\n",
    "        st.warning(\"No hay datos v√°lidos para las variables seleccionadas en las ciudades elegidas.\")\n",
    "        st.stop()\n",
    "\n",
    "    # Ajuste por ciudad\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import r2_score\n",
    "    metrics_rows, preds_rows = [], []\n",
    "    for c in sorted(data_lin[\"city\"].dropna().unique()):\n",
    "        d = data_lin[data_lin[\"city\"] == c]\n",
    "        if d.shape[0] < 2: continue\n",
    "        X, y = d[[x_var]].values, d[y_var].values\n",
    "        lr = LinearRegression().fit(X, y)\n",
    "        yhat = lr.predict(X)\n",
    "        r2 = r2_score(y, yhat)\n",
    "        try:\n",
    "            corr = np.corrcoef(d[x_var], d[y_var])[0, 1]\n",
    "            sign = np.sign(corr) if np.isfinite(corr) else 1\n",
    "        except Exception:\n",
    "            sign = 1\n",
    "        R = sign * np.sqrt(max(r2, 0))\n",
    "        metrics_rows.append({\"city\": c, \"R2\": round(r2, 4), \"R\": round(R, 4)})\n",
    "        xx = np.linspace(d[x_var].min(), d[x_var].max(), 120).reshape(-1, 1)\n",
    "        yy = lr.predict(xx)\n",
    "        preds_rows.append(pd.DataFrame({\"city\": c, x_var: xx.ravel(), \"y_pred\": yy}))\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_rows)\n",
    "    preds_df = pd.concat(preds_rows, ignore_index=True) if preds_rows else pd.DataFrame()\n",
    "    if metrics_df.empty:\n",
    "        st.warning(\"No fue posible ajustar modelos por falta de datos suficientes.\")\n",
    "        st.stop()\n",
    "\n",
    "    # Visualizaci√≥n facetada grande\n",
    "    fig_sc = px.scatter(data_lin, x=x_var, y=y_var, facet_col=\"city\", facet_col_wrap=3,\n",
    "                        title=f\"Regresi√≥n Lineal Simple: {y_var} ~ {x_var}\",\n",
    "                        opacity=0.75, height=900, width=1500)\n",
    "    if not preds_df.empty:\n",
    "        fig_line = px.line(preds_df, x=x_var, y=\"y_pred\", facet_col=\"city\", facet_col_wrap=3)\n",
    "        for tr in fig_line.data: fig_sc.add_trace(tr)\n",
    "    fig_sc.update_traces(marker=dict(size=5))\n",
    "    fig_sc.update_layout(margin=dict(l=40, r=40, t=60, b=40))\n",
    "    st.plotly_chart(fig_sc, use_container_width=False)\n",
    "\n",
    "    st.markdown(\"#### üìä M√©tricas por ciudad\")\n",
    "    st.dataframe(metrics_df.sort_values(\"R2\", ascending=False).reset_index(drop=True), use_container_width=True)\n",
    "    \n",
    "# ============================================================\n",
    "# TAB 4 - Regresi√≥n M√∫ltiple (facet por ciudad, Plotly ampliado)\n",
    "# ============================================================\n",
    "with tabs[3]:\n",
    "    st.subheader(\"üßÆ Regresi√≥n M√∫ltiple (comparativo multi-ciudad)\")\n",
    "    st.caption(\"Selecciona Y y las X; facetas por ciudad (y_real vs y_pred) con m√©tricas R¬≤ y R.\")\n",
    "\n",
    "    try:\n",
    "        cities_sel = sel_cities\n",
    "    except NameError:\n",
    "        cities_sel = sorted(df_all[\"city\"].dropna().unique().tolist())\n",
    "\n",
    "    num_cols_all = df_all.select_dtypes(include=[\"int\", \"float\", \"Int64\", \"Float64\"]).columns.tolist()\n",
    "    if not num_cols_all:\n",
    "        st.warning(\"No hay columnas num√©ricas para ajustar una regresi√≥n m√∫ltiple.\")\n",
    "        st.stop()\n",
    "\n",
    "    try:\n",
    "        y_var\n",
    "    except NameError:\n",
    "        y_var = \"price\" if \"price\" in num_cols_all else num_cols_all[0]\n",
    "    try:\n",
    "        x_vars\n",
    "    except NameError:\n",
    "        x_vars = [c for c in num_cols_all if c != y_var][:3] or num_cols_all[:3]\n",
    "\n",
    "    y_var = st.selectbox(\"Variable Y (dependiente)\", options=num_cols_all,\n",
    "                         index=max(0, num_cols_all.index(y_var) if y_var in num_cols_all else 0),\n",
    "                         key=\"tab4_y_var\")\n",
    "    x_vars = st.multiselect(\"Variables X (explicativas)\", options=[c for c in num_cols_all if c != y_var],\n",
    "                            default=[c for c in x_vars if c in num_cols_all and c != y_var],\n",
    "                            key=\"tab4_x_vars\")\n",
    "    if not x_vars:\n",
    "        st.info(\"Selecciona al menos una variable explicativa (X).\")\n",
    "        st.stop()\n",
    "\n",
    "    cols_needed = [\"city\", y_var] + x_vars\n",
    "    data_mlr = df_all[df_all[\"city\"].isin(cities_sel)][cols_needed].copy()\n",
    "    for c in [y_var] + x_vars:\n",
    "        data_mlr[c] = pd.to_numeric(data_mlr[c], errors=\"coerce\")\n",
    "    data_mlr = data_mlr.dropna(subset=[y_var] + x_vars)\n",
    "    if data_mlr.empty or data_mlr.shape[0] < len(x_vars) + 2:\n",
    "        st.warning(\"No hay suficientes datos v√°lidos para ajustar la regresi√≥n m√∫ltiple.\")\n",
    "        st.stop()\n",
    "\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import r2_score\n",
    "    metrics_rows, avp_rows = [], []\n",
    "    for c in sorted(data_mlr[\"city\"].dropna().unique()):\n",
    "        d = data_mlr[data_mlr[\"city\"] == c].copy()\n",
    "        if d.shape[0] < len(x_vars) + 2: continue\n",
    "        X, y = d[x_vars].values, d[y_var].values\n",
    "        lr = LinearRegression().fit(X, y)\n",
    "        yhat = lr.predict(X)\n",
    "        r2 = r2_score(y, yhat)\n",
    "        corr = np.corrcoef(y, yhat)[0,1] if len(y) > 1 else np.nan\n",
    "        sign = np.sign(corr) if np.isfinite(corr) else 1\n",
    "        R = sign * np.sqrt(max(r2, 0))\n",
    "        metrics_rows.append({\"city\": c, \"R2\": round(r2, 4), \"R\": round(R, 4)})\n",
    "        avp_rows.append(pd.DataFrame({\"city\": c, \"y_real\": y, \"y_pred\": yhat}))\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_rows)\n",
    "    avp_df = pd.concat(avp_rows, ignore_index=True) if avp_rows else pd.DataFrame()\n",
    "    if avp_df.empty:\n",
    "        st.info(\"Sin suficientes datos por ciudad para graficar.\")\n",
    "        st.stop()\n",
    "\n",
    "    fig_mlr = px.scatter(avp_df, x=\"y_real\", y=\"y_pred\",\n",
    "                         facet_col=\"city\", facet_col_wrap=3,\n",
    "                         title=f\"Regresi√≥n M√∫ltiple: {y_var} vs Predicci√≥n (por ciudad)\",\n",
    "                         opacity=0.75, height=900, width=1500)\n",
    "    fig_mlr.update_traces(marker=dict(size=5))\n",
    "    fig_mlr.update_layout(margin=dict(l=40, r=40, t=60, b=40))\n",
    "    st.plotly_chart(fig_mlr, use_container_width=False)\n",
    "\n",
    "    st.markdown(\"#### üìä M√©tricas por ciudad\")\n",
    "    st.dataframe(metrics_df.sort_values(\"R2\", ascending=False).reset_index(drop=True), use_container_width=True)\n",
    "    \n",
    "# ============================================================\n",
    "# TAB 5 - Regresi√≥n No Lineal (facet por ciudad, Plotly ampliado)\n",
    "# ============================================================\n",
    "with tabs[4]:\n",
    "    st.subheader(\"üß≠ Regresi√≥n No Lineal (comparativo multi-ciudad)\")\n",
    "    st.caption(\"Selecciona X, Y y el modelo no lineal; facetas por ciudad, l√≠nea de ajuste y m√©tricas R¬≤ y R.\")\n",
    "\n",
    "    try:\n",
    "        cities_sel = sel_cities\n",
    "    except NameError:\n",
    "        cities_sel = sorted(df_all[\"city\"].dropna().unique().tolist())\n",
    "\n",
    "    num_cols_all = df_all.select_dtypes(include=[\"int\", \"float\", \"Int64\", \"Float64\"]).columns.tolist()\n",
    "    if not num_cols_all:\n",
    "        st.warning(\"No hay columnas num√©ricas para ajustar una regresi√≥n no lineal.\")\n",
    "        st.stop()\n",
    "\n",
    "    try:\n",
    "        x_var\n",
    "    except NameError:\n",
    "        x_var = \"availability_365\" if \"availability_365\" in num_cols_all else num_cols_all[0]\n",
    "    try:\n",
    "        y_var\n",
    "    except NameError:\n",
    "        y_var = \"price\" if \"price\" in num_cols_all else (num_cols_all[1] if len(num_cols_all)>1 else num_cols_all[0])\n",
    "    modelos_disp = [\"cuadr√°tica\", \"logar√≠tmica\", \"exponencial\", \"lineal\"]\n",
    "    try:\n",
    "        modelo\n",
    "    except NameError:\n",
    "        modelo = \"cuadr√°tica\"\n",
    "\n",
    "    x_var = st.selectbox(\"Variable X (independiente)\", options=num_cols_all,\n",
    "                         index=max(0, num_cols_all.index(x_var) if x_var in num_cols_all else 0),\n",
    "                         key=\"tab5_x_var\")\n",
    "    y_var = st.selectbox(\"Variable Y (dependiente)\", options=num_cols_all,\n",
    "                         index=max(0, num_cols_all.index(y_var) if y_var in num_cols_all else (1 if len(num_cols_all)>1 else 0)),\n",
    "                         key=\"tab5_y_var\")\n",
    "    modelo = st.selectbox(\"Modelo\", options=modelos_disp,\n",
    "                          index=modelos_disp.index(modelo) if modelo in modelos_disp else 0,\n",
    "                          key=\"tab5_modelo\")\n",
    "\n",
    "    if x_var == y_var:\n",
    "        st.info(\"Selecciona variables distintas para X e Y.\")\n",
    "        st.stop()\n",
    "\n",
    "    data_nl = df_all[df_all[\"city\"].isin(cities_sel)][[\"city\", x_var, y_var]].copy()\n",
    "    data_nl[x_var] = pd.to_numeric(data_nl[x_var], errors=\"coerce\")\n",
    "    data_nl[y_var] = pd.to_numeric(data_nl[y_var], errors=\"coerce\")\n",
    "    data_nl = data_nl.dropna(subset=[x_var, y_var])\n",
    "    if data_nl.empty:\n",
    "        st.warning(\"No hay datos v√°lidos para las variables seleccionadas.\")\n",
    "        st.stop()\n",
    "\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import r2_score\n",
    "    metrics_rows, preds_rows = [], []\n",
    "\n",
    "    def fit_predict_model(d, modelo_sel):\n",
    "        X = d[[x_var]].values\n",
    "        y = d[y_var].values\n",
    "        if modelo_sel == \"cuadr√°tica\":\n",
    "            X_ = np.c_[X, X**2]; lr = LinearRegression().fit(X_, y); return lr, (lambda xx: lr.predict(np.c_[xx, xx**2]))\n",
    "        elif modelo_sel == \"logar√≠tmica\":\n",
    "            if (d[x_var] <= 0).any(): return None, None\n",
    "            X_ = np.log(X); lr = LinearRegression().fit(X_, y); return lr, (lambda xx: lr.predict(np.log(xx)))\n",
    "        elif modelo_sel == \"exponencial\":\n",
    "            if (d[y_var] <= 0).any(): return None, None\n",
    "            lr = LinearRegression().fit(X, np.log(y)); return lr, (lambda xx: np.exp(lr.predict(xx)))\n",
    "        else:\n",
    "            lr = LinearRegression().fit(X, y); return lr, (lambda xx: lr.predict(xx))\n",
    "\n",
    "    for c in sorted(data_nl[\"city\"].dropna().unique()):\n",
    "        d = data_nl[data_nl[\"city\"] == c].copy()\n",
    "        if d.shape[0] < 2: continue\n",
    "        lr, f_pred = fit_predict_model(d, modelo)\n",
    "        if lr is None: continue\n",
    "        X = d[[x_var]].values; y = d[y_var].values; yhat = f_pred(X)\n",
    "        r2 = r2_score(y, yhat)\n",
    "        corr = np.corrcoef(d[x_var], y)[0,1] if len(d)>1 else np.nan\n",
    "        sign = np.sign(corr) if np.isfinite(corr) else 1\n",
    "        R = sign * np.sqrt(max(r2, 0))\n",
    "        metrics_rows.append({\"city\": c, \"R2\": round(r2,4), \"R\": round(R,4)})\n",
    "        xx = np.linspace(d[x_var].min(), d[x_var].max(), 120).reshape(-1,1)\n",
    "        yy = f_pred(xx)\n",
    "        preds_rows.append(pd.DataFrame({\"city\": c, x_var: xx.ravel(), \"y_pred\": yy}))\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_rows)\n",
    "    preds_df = pd.concat(preds_rows, ignore_index=True) if preds_rows else pd.DataFrame()\n",
    "\n",
    "    fig_sc = px.scatter(data_nl, x=x_var, y=y_var, facet_col=\"city\", facet_col_wrap=3,\n",
    "                        title=f\"Regresi√≥n No Lineal ({modelo}): {y_var} ~ {x_var}\",\n",
    "                        opacity=0.75, height=900, width=1500)\n",
    "    if not preds_df.empty:\n",
    "        fig_line = px.line(preds_df, x=x_var, y=\"y_pred\",\n",
    "                           facet_col=\"city\", facet_col_wrap=3)\n",
    "        for tr in fig_line.data: fig_sc.add_trace(tr)\n",
    "    fig_sc.update_traces(marker=dict(size=5))\n",
    "    fig_sc.update_layout(margin=dict(l=40, r=40, t=60, b=40))\n",
    "    st.plotly_chart(fig_sc, use_container_width=False)\n",
    "\n",
    "    st.markdown(\"#### üìä M√©tricas por ciudad\")\n",
    "    if metrics_df.empty:\n",
    "        st.info(\"No se pudieron calcular m√©tricas (revisa datos/modelo).\")\n",
    "    else:\n",
    "        st.dataframe(metrics_df.sort_values(\"R2\", ascending=False).reset_index(drop=True), use_container_width=True)\n",
    "        \n",
    "# ============================================================\n",
    "# TAB 6 - Regresi√≥n Log√≠stica (facet por ciudad, Plotly ampliado)\n",
    "# ============================================================\n",
    "with tabs[5]:\n",
    "    st.subheader(\"üß™ Regresi√≥n Log√≠stica (comparativo multi-ciudad)\")\n",
    "    st.caption(\"Selecciona la Y binaria y las X; curvas ROC por ciudad en facetas y m√©tricas AUC/Precision/Recall/F1.\")\n",
    "\n",
    "    try:\n",
    "        cities_sel = sel_cities\n",
    "    except NameError:\n",
    "        cities_sel = sorted(df_all[\"city\"].dropna().unique().tolist())\n",
    "\n",
    "    # Y binaria y X_vars seguros\n",
    "    try:\n",
    "        y_bin\n",
    "    except NameError:\n",
    "        y_bin = \"host_is_superhost\" if \"host_is_superhost\" in df_all.columns else None\n",
    "\n",
    "    num_cols_all = df_all.select_dtypes(include=[\"int\", \"float\", \"Int64\", \"Float64\"]).columns.tolist()\n",
    "    try:\n",
    "        X_vars\n",
    "    except NameError:\n",
    "        X_vars = [c for c in [\"price\",\"availability_365\",\"number_of_reviews\"] if c in num_cols_all] or num_cols_all[:2]\n",
    "\n",
    "    # Selector de Y binaria\n",
    "    if y_bin is None or y_bin not in df_all.columns:\n",
    "        bin_candidates = [c for c in df_all.columns if df_all[c].dropna().astype(str).str.lower().isin([\"0\",\"1\",\"t\",\"f\",\"true\",\"false\",\"yes\",\"no\",\"si\",\"s√≠\"]).any()]\n",
    "        if not bin_candidates:\n",
    "            st.warning(\"No se detect√≥ una columna binaria para Y. Define y_bin o crea una binarizaci√≥n en tu Tab de Log√≠stica.\")\n",
    "            st.stop()\n",
    "        y_bin = st.selectbox(\"Variable Y binaria\", options=bin_candidates, index=0, key=\"tab6_y_bin\")\n",
    "    else:\n",
    "        all_opts = [y_bin] + [c for c in df_all.columns if c != y_bin]\n",
    "        y_bin = st.selectbox(\"Variable Y binaria\", options=all_opts, index=0, key=\"tab6_y_bin_fixed\")\n",
    "\n",
    "    # Select Xs\n",
    "    X_vars = st.multiselect(\"Variables X (explicativas)\", options=[c for c in num_cols_all if c != y_bin],\n",
    "                            default=[x for x in X_vars if x in num_cols_all and x != y_bin],\n",
    "                            key=\"tab6_x_vars\")\n",
    "    if not X_vars:\n",
    "        st.info(\"Selecciona al menos una variable explicativa (X).\")\n",
    "        st.stop()\n",
    "\n",
    "    # Par√°metros de entrenamiento\n",
    "    try:\n",
    "        class_weight_opt\n",
    "    except NameError:\n",
    "        class_weight_opt = \"balanced\"\n",
    "    try:\n",
    "        threshold_opt\n",
    "    except NameError:\n",
    "        threshold_opt = 0.5\n",
    "\n",
    "    class_weight_opt = st.selectbox(\"class_weight\", options=[\"none\",\"balanced\"],\n",
    "                                    index=1 if class_weight_opt in [\"balanced\"] else 0,\n",
    "                                    key=\"tab6_class_weight\")\n",
    "    threshold_opt = st.number_input(\"Umbral de clasificaci√≥n (0‚Äì1)\", min_value=0.0, max_value=1.0,\n",
    "                                    value=float(threshold_opt), step=0.05, key=\"tab6_threshold\")\n",
    "\n",
    "    # Preparaci√≥n de datos\n",
    "    cols_needed = [\"city\", y_bin] + X_vars\n",
    "    data_log = df_all[df_all[\"city\"].isin(cities_sel)][cols_needed].copy()\n",
    "\n",
    "    # Y binaria robusta\n",
    "    y_raw = data_log[y_bin].astype(str).str.strip().str.lower()\n",
    "    y_num = np.where(y_raw.isin([\"1\",\"t\",\"true\",\"yes\",\"si\",\"s√≠\",\"y\",\"s\"]), 1,\n",
    "                     np.where(y_raw.isin([\"0\",\"f\",\"false\",\"no\",\"n\"]), 0, np.nan))\n",
    "    data_log[y_bin] = pd.to_numeric(y_num, errors=\"coerce\")\n",
    "\n",
    "    # X num√©rico\n",
    "    for c in X_vars:\n",
    "        data_log[c] = pd.to_numeric(data_log[c], errors=\"coerce\")\n",
    "\n",
    "    data_log = data_log.dropna(subset=[y_bin] + X_vars)\n",
    "    if data_log.empty or data_log[y_bin].nunique() < 2:\n",
    "        st.warning(\"No hay suficientes datos/variabilidad en la Y binaria para ajustar la log√≠stica.\")\n",
    "        st.stop()\n",
    "\n",
    "    # Ajuste por ciudad + ROC facet\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_fscore_support\n",
    "\n",
    "    metrics_rows, roc_rows = [], []\n",
    "    for c in sorted(data_log[\"city\"].dropna().unique()):\n",
    "        d = data_log[data_log[\"city\"] == c].copy()\n",
    "        if d[y_bin].nunique() < 2 or d.shape[0] < len(X_vars) + 2: continue\n",
    "\n",
    "        X, y = d[X_vars].values, d[y_bin].astype(int).values\n",
    "        cw = None if class_weight_opt in [\"none\", None, \"\"] else class_weight_opt\n",
    "        lr = LogisticRegression(max_iter=500, class_weight=cw)\n",
    "        lr.fit(X, y)\n",
    "        proba = lr.predict_proba(X)[:, 1]\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y, proba)\n",
    "        auc = roc_auc_score(y, proba)\n",
    "        roc_rows.append(pd.DataFrame({\"city\": c, \"fpr\": fpr, \"tpr\": tpr, \"auc\": auc}))\n",
    "\n",
    "        thr = float(threshold_opt)\n",
    "        yhat = (proba >= thr).astype(int)\n",
    "        prec, rec, f1, _ = precision_recall_fscore_support(y, yhat, average=\"binary\", zero_division=0)\n",
    "        metrics_rows.append({\"city\": c, \"AUC\": round(auc,4), \"Precision\": round(prec,4), \"Recall\": round(rec,4), \"F1\": round(f1,4)})\n",
    "\n",
    "    roc_df = pd.concat(roc_rows, ignore_index=True) if roc_rows else pd.DataFrame()\n",
    "    metrics_df = pd.DataFrame(metrics_rows) if metrics_rows else pd.DataFrame(columns=[\"city\",\"AUC\",\"Precision\",\"Recall\",\"F1\"])\n",
    "\n",
    "    if roc_df.empty:\n",
    "        st.info(\"No hay suficientes datos para graficar ROC por ciudad.\")\n",
    "    else:\n",
    "        fig_roc = px.area(roc_df, x=\"fpr\", y=\"tpr\",\n",
    "                          facet_col=\"city\", facet_col_wrap=3,\n",
    "                          title=\"Regresi√≥n Log√≠stica: Curvas ROC por ciudad\",\n",
    "                          hover_data={\"auc\":\":.3f\"}, height=900, width=1500)\n",
    "        fig_roc.update_layout(margin=dict(l=40, r=40, t=60, b=40))\n",
    "        st.plotly_chart(fig_roc, use_container_width=False)\n",
    "\n",
    "    st.markdown(\"#### üìä M√©tricas por ciudad\")\n",
    "    st.dataframe(metrics_df.sort_values(\"AUC\", ascending=False).reset_index(drop=True),\n",
    "                 use_container_width=True)\n",
    "\n",
    "# ============================================================\n",
    "# TAB 7 - Insights & Propuestas\n",
    "# ============================================================\n",
    "with tabs[6]:\n",
    "    st.subheader(\"üìä Insights y Recomendaciones Estrat√©gicas\")\n",
    "    st.caption(\"Comparaci√≥n de medias entre ciudades usando variables reconstruidas desde los datasets originales (sin intersecci√≥n). Incluye % de Superhosts (T).\")\n",
    "\n",
    "    import re, unicodedata\n",
    "\n",
    "    # ---- Utilidades robustas ----\n",
    "    def _norm_txt(s: str) -> str:\n",
    "        s = str(s)\n",
    "        s = unicodedata.normalize(\"NFKD\", s)\n",
    "        s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
    "        return s.strip().lower()\n",
    "\n",
    "    def is_mex(name: str) -> bool:\n",
    "        n = _norm_txt(name)\n",
    "        return bool(\n",
    "            re.search(r\"^mex\", n) or\n",
    "            re.search(r\"ciudad\\s*de\\s*mex\", n) or\n",
    "            re.search(r\"\\bcdmx\\b\", n) or\n",
    "            re.fullmatch(r\"mx\", n)\n",
    "        )\n",
    "\n",
    "    def find_col(df_local, aliases):\n",
    "        cols = list(df_local.columns)\n",
    "        low = [c.strip().lower() for c in cols]\n",
    "        # exacta\n",
    "        for a in aliases:\n",
    "            a2 = a.strip().lower()\n",
    "            if a2 in low:\n",
    "                return cols[low.index(a2)]\n",
    "        # inclusi√≥n parcial\n",
    "        for a in aliases:\n",
    "            a2 = a.strip().lower()\n",
    "            for i, c in enumerate(low):\n",
    "                if a2 in c:\n",
    "                    return cols[i]\n",
    "        return None\n",
    "\n",
    "    def clean_numeric_like(series):\n",
    "        s = series.astype(str).str.replace(r\"[^\\d,.\\-]\", \"\", regex=True)\n",
    "        mask_coma_decimal = ~s.str.contains(r\"\\.\") & s.str.contains(\",\")\n",
    "        s.loc[mask_coma_decimal] = s.loc[mask_coma_decimal].str.replace(\",\", \".\", regex=False)\n",
    "        s = s.str.replace(\",\", \"\", regex=False)\n",
    "        return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "    # ---- Aliases por variable ----\n",
    "    alias = {\n",
    "        \"host_is_superhost\": [\"host_is_superhost\", \"is_superhost\", \"superhost\"],\n",
    "        \"host_response_time\": [\"host_response_time\", \"response_time\", \"tiempo_respuesta\"],\n",
    "        \"calculated_host_listings_count\": [\"calculated_host_listings_count\", \"host_total_listings_count\"],\n",
    "        \"price\": [\"price\", \"precio\"],\n",
    "        \"number_of_reviews\": [\"number_of_reviews\", \"reviews\"],\n",
    "        \"availability_365\": [\"availability_365\"],\n",
    "    }\n",
    "\n",
    "    # ---- Reconstrucci√≥n desde dfs_raw ----\n",
    "    recs = []       # filas unificadas\n",
    "    mappings = []   # mapeo por dataset\n",
    "\n",
    "    for d in dfs_raw:\n",
    "        if d is None or d.empty or \"city\" not in d.columns:\n",
    "            continue\n",
    "        df_local = d.copy()\n",
    "        df_local.columns = [str(c).strip() for c in df_local.columns]\n",
    "\n",
    "        tmp = pd.DataFrame()\n",
    "        tmp[\"city\"] = df_local[\"city\"].astype(str)\n",
    "\n",
    "        # host_is_superhost (con regla para M√©xico)\n",
    "        col_hsh = find_col(df_local, alias[\"host_is_superhost\"])\n",
    "        if col_hsh:\n",
    "            raw = df_local[col_hsh].astype(str).str.strip().str.lower()\n",
    "            # m√°scara M√©xico\n",
    "            mex_mask = tmp[\"city\"].map(is_mex).fillna(False)\n",
    "\n",
    "            # M√©xico: SOLO T/F/1/0 -> map estricta; resto NaN\n",
    "            map_mex = {\"t\": 1, \"f\": 0, \"1\": 1, \"0\": 0}\n",
    "            tmp.loc[mex_mask, \"host_is_superhost_num\"] = raw[mex_mask].map(map_mex)\n",
    "\n",
    "            # Otras ciudades: mapeo flexible cl√°sico\n",
    "            oth = ~mex_mask\n",
    "            tmp.loc[oth, \"host_is_superhost_num\"] = np.where(\n",
    "                raw[oth].isin([\"t\",\"true\",\"1\",\"yes\",\"si\",\"s√≠\",\"y\",\"s\"]), 1,\n",
    "                np.where(raw[oth].isin([\"f\",\"false\",\"0\",\"no\",\"n\"]), 0, np.nan)\n",
    "            )\n",
    "\n",
    "            # Tambi√©n versi√≥n F/T para diagn√≥stico y visual\n",
    "            tmp[\"host_is_superhost_str\"] = tmp[\"host_is_superhost_num\"].map({1.0: \"T\", 0.0: \"F\"})\n",
    "        else:\n",
    "            tmp[\"host_is_superhost_num\"] = np.nan\n",
    "            tmp[\"host_is_superhost_str\"] = np.nan\n",
    "\n",
    "        # host_response_time -> ordinal 4..1\n",
    "        col_rt = find_col(df_local, alias[\"host_response_time\"])\n",
    "        if col_rt:\n",
    "            m = {\n",
    "                \"within an hour\": 4, \"within a few hours\": 3,\n",
    "                \"within a day\": 2, \"a few days or more\": 1\n",
    "            }\n",
    "            tmp[\"host_response_time\"] = (\n",
    "                df_local[col_rt].astype(str).str.strip().str.lower().map(m)\n",
    "            )\n",
    "        else:\n",
    "            tmp[\"host_response_time\"] = np.nan\n",
    "\n",
    "        # calculated_host_listings_count\n",
    "        col_chl = find_col(df_local, alias[\"calculated_host_listings_count\"])\n",
    "        if col_chl:\n",
    "            tmp[\"calculated_host_listings_count\"] = pd.to_numeric(df_local[col_chl], errors=\"coerce\")\n",
    "        else:\n",
    "            tmp[\"calculated_host_listings_count\"] = np.nan\n",
    "\n",
    "        # price (limpieza general; NaN se ignoran en medias; caso Valencia ya cubierto)\n",
    "        col_price = find_col(df_local, alias[\"price\"])\n",
    "        if col_price:\n",
    "            tmp[\"price\"] = clean_numeric_like(df_local[col_price])\n",
    "        else:\n",
    "            tmp[\"price\"] = np.nan\n",
    "\n",
    "        # number_of_reviews\n",
    "        col_nor = find_col(df_local, alias[\"number_of_reviews\"])\n",
    "        if col_nor:\n",
    "            tmp[\"number_of_reviews\"] = pd.to_numeric(df_local[col_nor], errors=\"coerce\")\n",
    "        else:\n",
    "            tmp[\"number_of_reviews\"] = np.nan\n",
    "\n",
    "        # availability_365\n",
    "        col_av = find_col(df_local, alias[\"availability_365\"])\n",
    "        if col_av:\n",
    "            tmp[\"availability_365\"] = pd.to_numeric(df_local[col_av], errors=\"coerce\")\n",
    "        else:\n",
    "            tmp[\"availability_365\"] = np.nan\n",
    "\n",
    "        recs.append(tmp)\n",
    "\n",
    "        # mapeo informativo\n",
    "        maps = {\n",
    "            \"Ciudad(es) en DF\": \", \".join(sorted(tmp[\"city\"].astype(str).unique())),\n",
    "            \"host_is_superhost <-\": col_hsh if col_hsh else \"‚ùå\",\n",
    "            \"host_response_time <-\": col_rt if col_rt else \"‚ùå\",\n",
    "            \"calculated_host_listings_count <-\": col_chl if col_chl else \"‚ùå\",\n",
    "            \"price <-\": col_price if col_price else \"‚ùå\",\n",
    "            \"number_of_reviews <-\": col_nor if col_nor else \"‚ùå\",\n",
    "            \"availability_365 <-\": col_av if col_av else \"‚ùå\",\n",
    "        }\n",
    "        mappings.append(maps)\n",
    "\n",
    "    if not recs:\n",
    "        st.warning(\"No hay datos disponibles para generar insights.\")\n",
    "        st.stop()\n",
    "\n",
    "    df_ins = pd.concat(recs, ignore_index=True)\n",
    "    # Filtra por las ciudades seleccionadas\n",
    "    df_ins = df_ins[df_ins[\"city\"].isin(sel_cities)].copy()\n",
    "\n",
    "    # ---- Diagn√≥stico de mapeos ----\n",
    "    with st.expander(\"üîé Mapeo de columnas utilizadas por dataset\"):\n",
    "        st.dataframe(pd.DataFrame(mappings), use_container_width=True)\n",
    "\n",
    "    # ---- Tabla de diagn√≥stico Superhosts F/T por ciudad ----\n",
    "    with st.expander(\"üîç Distribuci√≥n F/T por ciudad (host_is_superhost)\"):\n",
    "        if \"host_is_superhost_str\" in df_ins.columns:\n",
    "            diag = (\n",
    "                df_ins.groupby([\"city\", \"host_is_superhost_str\"])\n",
    "                .size()\n",
    "                .unstack(fill_value=0)\n",
    "                .rename(columns={\"F\": \"F (No)\", \"T\": \"T (S√≠)\"})\n",
    "            )\n",
    "            st.dataframe(diag, use_container_width=True)\n",
    "\n",
    "    # ---- C√°lculo de medias por ciudad ----\n",
    "    metrics = [\"host_is_superhost_num\", \"host_response_time\",\n",
    "               \"calculated_host_listings_count\", \"price\",\n",
    "               \"number_of_reviews\", \"availability_365\"]\n",
    "\n",
    "    summary = {}\n",
    "    for v in metrics:\n",
    "        if v in df_ins.columns:\n",
    "            df_ins[v] = pd.to_numeric(df_ins[v], errors=\"coerce\")\n",
    "            mean_v = df_ins.groupby(\"city\")[v].mean().round(2)\n",
    "            if mean_v.notna().any():\n",
    "                summary[v] = mean_v\n",
    "\n",
    "    if not summary:\n",
    "        st.warning(\"No fue posible calcular medias (todas las series vac√≠as).\")\n",
    "        st.stop()\n",
    "\n",
    "    df_summary = pd.DataFrame(summary).sort_index()\n",
    "\n",
    "    # Porcentaje de Superhosts (T) por ciudad\n",
    "    if \"host_is_superhost_num\" in df_summary.columns:\n",
    "        df_summary[\"%_superhosts\"] = (df_summary[\"host_is_superhost_num\"] * 100).round(1)\n",
    "\n",
    "    st.markdown(\"### üìà Comparativo de medias entre ciudades\")\n",
    "    st.dataframe(df_summary, use_container_width=True)\n",
    "\n",
    "    # ---- Gr√°ficas ----\n",
    "    # Hosts\n",
    "    st.markdown(\"#### üßë‚Äçüíº M√©tricas de Hosts\")\n",
    "    for v, title in [\n",
    "        (\"host_is_superhost_num\", \"% Superhosts (promedio 0/1)\"),\n",
    "        (\"host_response_time\", \"Rapidez de respuesta (4=mejor)\"),\n",
    "        (\"calculated_host_listings_count\", \"Propiedades por host (promedio)\"),\n",
    "    ]:\n",
    "        if v in df_summary.columns:\n",
    "            fig = px.bar(df_summary.reset_index(), x=\"city\", y=v, color=\"city\",\n",
    "                         title=f\"{title} ‚Äî promedio por ciudad\")\n",
    "            st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    # Hospedaje\n",
    "    st.markdown(\"#### üè† M√©tricas de Hospedaje\")\n",
    "    for v, title in [\n",
    "        (\"price\", \"Precio promedio\"),\n",
    "        (\"number_of_reviews\", \"Rese√±as promedio\"),\n",
    "        (\"availability_365\", \"Disponibilidad promedio (d√≠as)\"),\n",
    "    ]:\n",
    "        if v in df_summary.columns:\n",
    "            fig = px.bar(df_summary.reset_index(), x=\"city\", y=v, color=\"city\",\n",
    "                         title=f\"{title} ‚Äî promedio por ciudad\")\n",
    "            st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    # ---- Recomendaciones ----\n",
    "    st.markdown(\"### üß≠ Recomendaciones Estrat√©gicas\")\n",
    "    recs = []\n",
    "    if \"%_superhosts\" in df_summary.columns:\n",
    "        minc = df_summary[\"%_superhosts\"].idxmin()\n",
    "        recs.append(f\"- **{minc}**: impulsar la ruta a Superhost (mentor√≠a + checklist de amenities) para elevar el % de superhosts.\")\n",
    "    if \"host_response_time\" in df_summary.columns:\n",
    "        minr = df_summary[\"host_response_time\"].idxmin()\n",
    "        recs.append(f\"- **{minr}**: activar respuestas autom√°ticas y recordatorios para mejorar tiempos de respuesta de hosts.\")\n",
    "    if \"availability_365\" in df_summary.columns:\n",
    "        maxa = df_summary[\"availability_365\"].idxmax()\n",
    "        recs.append(f\"- **{maxa}**: aplicar pricing din√°mico y promos de temporada baja para reducir vacancia anual.\")\n",
    "    if \"price\" in df_summary.columns:\n",
    "        maxp = df_summary[\"price\"].idxmax()\n",
    "        recs.append(f\"- **{maxp}**: consolidar oferta premium y low-budget (bundles: late checkout, limpieza) como estrategia comercial.\")\n",
    "    if \"number_of_reviews\" in df_summary.columns:\n",
    "        minrv = df_summary[\"number_of_reviews\"].idxmin()\n",
    "        recs.append(f\"- **{minrv}**: campa√±as de visibilidad + recordatorios post-estancia para aumentar rese√±as.\")\n",
    "    if \"calculated_host_listings_count\" in df_summary.columns:\n",
    "        maxh = df_summary[\"calculated_host_listings_count\"].idxmax()\n",
    "        recs.append(f\"- **{maxh}**: estrategia de diversificaci√≥n de alojamientos.\")\n",
    "\n",
    "    for r in recs:\n",
    "        st.markdown(r)\n",
    "\n",
    "    st.success(\"‚úÖ host_is_superhost de M√âXICO tomado correctamente (solo T/F/1/0) y % de T por ciudad calculado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
