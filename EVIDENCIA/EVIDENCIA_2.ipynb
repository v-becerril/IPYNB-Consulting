{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "038d22d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: streamlit in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.50.0)\n",
      "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (1.9.0)\n",
      "Requirement already satisfied: cachetools<7,>=4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (6.2.1)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (8.3.0)\n",
      "Requirement already satisfied: numpy<3,>=1.23 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (2.3.4)\n",
      "Requirement already satisfied: packaging<26,>=20 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from streamlit) (25.0)\n",
      "Requirement already satisfied: pandas<3,>=1.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (2.3.3)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (11.3.0)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (6.33.0)\n",
      "Requirement already satisfied: pyarrow>=7.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (21.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.27 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (2.32.5)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (9.1.2)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (4.15.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (3.1.45)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from streamlit) (0.9.1)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from streamlit) (6.5.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.8.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (2.3.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from seaborn) (2.3.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from seaborn) (3.10.7)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: plotly in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (6.3.1)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from plotly) (2.8.0)\n",
      "Requirement already satisfied: packaging in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from plotly) (25.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: statsmodels in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.14.5)\n",
      "Requirement already satisfied: numpy<3,>=1.22.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from statsmodels) (2.3.4)\n",
      "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from statsmodels) (1.16.2)\n",
      "Requirement already satisfied: pandas!=2.1.0,>=1.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from statsmodels) (2.3.3)\n",
      "Requirement already satisfied: patsy>=0.5.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from statsmodels) (1.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from statsmodels) (25.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Users/juanpablopineroillescas/Library/Python/3.12/lib/python/site-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3.12 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K\n",
      "up to date, audited 23 packages in 897ms\n",
      "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K\n",
      "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K3 packages are looking for funding\n",
      "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K  run `npm fund` for details\n",
      "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K\n",
      "2 \u001b[31m\u001b[1mhigh\u001b[22m\u001b[39m severity vulnerabilities\n",
      "\n",
      "To address all issues (including breaking changes), run:\n",
      "  npm audit fix --force\n",
      "\n",
      "Run `npm audit` for details.\n",
      "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K"
     ]
    }
   ],
   "source": [
    "%pip install streamlit\n",
    "%pip install matplotlib\n",
    "%pip install seaborn\n",
    "%pip install scikit-learn\n",
    "%pip install plotly\n",
    "%pip install statsmodels\n",
    "\n",
    "#Para instalar npm en visual studio\n",
    "#1.Desde Google escribir node.js\n",
    "#2. Instalar la versión más recomendada\n",
    "! npm install localtunnel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5e50a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting EVIDENCIA_2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile EVIDENCIA_2.py\n",
    "\n",
    "## streamlit run EVIDENCIA_2.py\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import streamlit as st\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    r2_score, mean_absolute_error, mean_squared_error,\n",
    "    precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, roc_curve\n",
    ")\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# =========================\n",
    "# Utilidades base\n",
    "# =========================\n",
    "def safe_read_csv(path):\n",
    "    try:\n",
    "        if os.path.exists(path):\n",
    "            return pd.read_csv(path)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def unify_schema(df, city_name=None, verbose=False):\n",
    "    \"\"\"\n",
    "    Normaliza nombres, resuelve columnas duplicadas, agrega 'city',\n",
    "    y convierte strings con '%' a numéricos. Evita AttributeError.\n",
    "    \"\"\"\n",
    "    if df is None or len(df) == 0:\n",
    "        return None\n",
    "\n",
    "    # 1) Normaliza nombres a snake_case\n",
    "    cols_raw = list(df.columns)\n",
    "    norm_cols = [str(c).strip().lower().replace(\" \", \"_\") for c in cols_raw]\n",
    "\n",
    "    # 2) Unifica duplicados: col, col__1, col__2, ...\n",
    "    seen = {}\n",
    "    unique_cols = []\n",
    "    dups = []\n",
    "    for c in norm_cols:\n",
    "        if c not in seen:\n",
    "            seen[c] = 0\n",
    "            unique_cols.append(c)\n",
    "        else:\n",
    "            seen[c] += 1\n",
    "            new_c = f\"{c}__{seen[c]}\"\n",
    "            unique_cols.append(new_c)\n",
    "            dups.append((c, new_c))\n",
    "    if verbose and dups:\n",
    "        print(\"Columnas duplicadas renombradas:\", dups)\n",
    "\n",
    "    df = df.copy()\n",
    "    df.columns = unique_cols\n",
    "\n",
    "    # 3) Correcciones habituales\n",
    "    ren = {\n",
    "        \"accomodates\": \"accommodates\",\n",
    "        \"bedroms\": \"bedrooms\",\n",
    "        \"bathroom\": \"bathrooms\",\n",
    "        \"host_response_time(%)\": \"host_response_rate\",\n",
    "        \"review_scores_value\": \"review_scores_rating\"\n",
    "    }\n",
    "    for k, v in ren.items():\n",
    "        if k in df.columns and v not in df.columns:\n",
    "            df.rename(columns={k: v}, inplace=True)\n",
    "\n",
    "    # 4) Asegura 'city'\n",
    "    if \"city\" not in df.columns:\n",
    "        df[\"city\"] = city_name if city_name else \"unknown\"\n",
    "    else:\n",
    "        if city_name:\n",
    "            df[\"city\"] = df[\"city\"].fillna(city_name).replace(\"\", city_name)\n",
    "\n",
    "    # 5) Convierte columnas con símbolo %\n",
    "    for c in df.columns:\n",
    "        s = df[c]\n",
    "        if pd.api.types.is_object_dtype(s):\n",
    "            if s.astype(str).str.contains(\"%\").any():\n",
    "                s2 = s.astype(str).str.replace(\"%\", \"\", regex=False)\n",
    "                s2 = pd.to_numeric(s2, errors=\"coerce\")\n",
    "                df[c] = s2\n",
    "\n",
    "    return df\n",
    "\n",
    "def numeric_cols(df):\n",
    "    return [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "\n",
    "def categorical_cols(df):\n",
    "    return [c for c in df.columns if (df[c].dtype == \"object\" or str(df[c].dtype).startswith(\"category\"))]\n",
    "\n",
    "def r_from_y_ypred(y_true, y_pred):\n",
    "    if len(y_true) < 2 or len(y_pred) < 2:\n",
    "        return np.nan\n",
    "    try:\n",
    "        return float(np.corrcoef(y_true, y_pred)[0,1])\n",
    "    except Exception:\n",
    "        return np.nan\n",
    "\n",
    "def fit_nonlinear_series(x, y, model_name):\n",
    "    def f_quad(z, a, b, c): return a*z**2 + b*z + c\n",
    "    def f_exp(z, a, b, c):  return a*np.exp(b*z) + c\n",
    "    def f_inv(z, a, b):     return a + b/np.where(z==0, np.finfo(float).eps, z)\n",
    "\n",
    "    if model_name == \"Cuadrática\":\n",
    "        popt, _ = curve_fit(f_quad, x, y, maxfev=20000)\n",
    "        yhat = f_quad(x, *popt)\n",
    "        return yhat, popt\n",
    "    elif model_name == \"Exponencial\":\n",
    "        p0 = (1.0, 0.01, float(np.nanmedian(y)))\n",
    "        popt, _ = curve_fit(f_exp, x, y, p0=p0, maxfev=20000)\n",
    "        yhat = f_exp(x, *popt)\n",
    "        return yhat, popt\n",
    "    else:  # Inversa\n",
    "        popt, _ = curve_fit(f_inv, x, y, maxfev=20000)\n",
    "        yhat = f_inv(x, *popt)\n",
    "        return yhat, popt\n",
    "\n",
    "def coerce_numeric_cols(df, cols):\n",
    "    \"\"\"Devuelve una copia donde 'cols' se convierten a numérico con errors='coerce'.\"\"\"\n",
    "    d = df.copy()\n",
    "    for c in cols:\n",
    "        if c in d.columns:\n",
    "            d[c] = pd.to_numeric(d[c], errors='coerce')\n",
    "    return d\n",
    "\n",
    "# =========================\n",
    "# Configuración app\n",
    "# =========================\n",
    "st.set_page_config(\n",
    "    page_title=\"Dashboard Mult-ciudad Airbnb: Proyecto Innovativo Grupo IPYNB\",\n",
    "    page_icon=\"🏠\",\n",
    "    layout=\"wide\"\n",
    ")\n",
    "\n",
    "# --- Portada (Imagen + Título + Descripción) ---\n",
    "# Ruta proporcionada por el usuario (cámbiala si tu archivo está en otra ubicación)\n",
    "PORTADA_PATHS = [\n",
    "    \"WhatsApp Image 2025-10-22 at 11.38.03 PM.jpeg\",\n",
    "    \"./assets/aura.jpg\",\n",
    "    \"./assets/aura.png\",\n",
    "    \"/mnt/data/WhatsApp Image 2025-10-22 at 11.38.03 PM.jpeg\",\n",
    "]\n",
    "img_path = next((p for p in PORTADA_PATHS if os.path.exists(p)), None)\n",
    "if img_path:\n",
    "    col_l, col_c, col_r = st.columns([1,2,1])\n",
    "    with col_c:\n",
    "        st.image(img_path, use_column_width=True)\n",
    "else:\n",
    "    st.info(\"⚠️ Imagen de portada no encontrada. Verifica la ruta en PORTADA_PATHS.\")\n",
    "\n",
    "st.title(\"Dashboard Mult-ciudad Airbnb: Proyecto Innovativo Grupo IPYNB\")\n",
    "st.write(\"**Este dashboard permite establecer un panorama completo de Airbnb, sus Hosts y Alojamientos, potencializando al Programa AURA.**\")\n",
    "\n",
    "# =========================\n",
    "# Sidebar\n",
    "# =========================\n",
    "with st.sidebar:\n",
    "    st.header(\"⚙️ Configuración\")\n",
    "    color = st.color_picker(\"Color principal\", \"#0B6E4F\")\n",
    "    grid_alpha = st.slider(\"Transparencia de rejilla\", 0.0, 1.0, 0.2, 0.05)\n",
    "    st.markdown(\"---\")\n",
    "    st.subheader(\"📂 Carga de datos (opcional)\")\n",
    "    ups = st.file_uploader(\"Sube CSV (puedes múltiples)\", type=[\"csv\"], accept_multiple_files=True)\n",
    "\n",
    "# =========================\n",
    "# Carga de datasets base\n",
    "# =========================\n",
    "df_mex = unify_schema(safe_read_csv(\"Mexico_Limpio_modified.csv\"), \"Mexico\")\n",
    "df_mad = unify_schema(safe_read_csv(\"Madrid_AirBnb_010.csv\"), \"Madrid\")\n",
    "df_val = unify_schema(safe_read_csv(\"VALENCIA_LIMPIO.csv\"), \"Valencia\")\n",
    "df_rio = unify_schema(safe_read_csv(\"base_final.csv\"), \"Rio\")   # <- etiqueta \"Rio\"\n",
    "df_roma = unify_schema(safe_read_csv(\"df_limp_ROMA.csv\"), \"Roma\")\n",
    "\n",
    "dfs_raw = [d for d in [df_mex, df_mad, df_val, df_rio, df_roma] if d is not None]\n",
    "\n",
    "if ups:\n",
    "    for f in ups:\n",
    "        try:\n",
    "            tmp = pd.read_csv(f)\n",
    "            dfs_raw.append(unify_schema(tmp, city_name=os.path.splitext(f.name)[0]))\n",
    "        except Exception as e:\n",
    "            st.warning(f\"No se pudo leer {f.name}: {e}\")\n",
    "\n",
    "if not dfs_raw:\n",
    "    st.error(\"No se encontraron datos. Coloca los CSV en la carpeta o súbelos.\")\n",
    "    st.stop()\n",
    "\n",
    "# Intersección de columnas comunes para asegurar comparabilidad\n",
    "common_cols = set(dfs_raw[0].columns)\n",
    "for d in dfs_raw[1:]:\n",
    "    common_cols = common_cols.intersection(set(d.columns))\n",
    "common_cols = sorted(list(common_cols))\n",
    "\n",
    "# Reindexa cada DF a columnas comunes\n",
    "dfs = [d[common_cols].copy() for d in dfs_raw]\n",
    "\n",
    "# Concat para análisis global\n",
    "df_all = pd.concat(dfs, ignore_index=True)\n",
    "cities_all = sorted(df_all[\"city\"].dropna().astype(str).unique().tolist())\n",
    "\n",
    "# Selección de ciudades a comparar\n",
    "sel_cities = st.multiselect(\"🌍 Ciudades a comparar\", options=cities_all, default=cities_all)\n",
    "if not sel_cities:\n",
    "    st.warning(\"Selecciona al menos una ciudad.\")\n",
    "    st.stop()\n",
    "df = df_all[df_all[\"city\"].isin(sel_cities)].reset_index(drop=True)\n",
    "\n",
    "# Columnas por tipo (en universo común)\n",
    "num_cols_all = [c for c in common_cols if pd.api.types.is_numeric_dtype(df[c])]\n",
    "cat_cols_all = [c for c in common_cols if (df[c].dtype == \"object\" or str(df[c].dtype).startswith(\"category\"))]\n",
    "\n",
    "# =========================\n",
    "# Tabs (7 secciones)\n",
    "# =========================\n",
    "tabs = st.tabs([\n",
    "    \"1) 🧰 Extracción\",\n",
    "    \"2) 🔠 Categóricas\",\n",
    "    \"3) 📈 Regresión Lineal Simple\",\n",
    "    \"4) 🧮 Regresión Lineal Múltiple\",\n",
    "    \"5) 🌀 Regresión No Lineal\",\n",
    "    \"6) 🧪 Regresión Logística\",\n",
    "    \"7) 💡 Insights & Propuestas\",\n",
    "])\n",
    "\n",
    "# ============================================================\n",
    "# TAB 1 - Extracción (comparativos de variables de servicio)\n",
    "# ============================================================\n",
    "with tabs[0]:\n",
    "    st.subheader(\"🧰 Extracción: comparativo de variables clave por ciudad\")\n",
    "    st.caption(\"Variables típicas: price, number_of_reviews, availability_365, calculated_host_listings_count, accommodates, reviews_per_month, minimum_nights, estimated_occupancy_l365d, review_scores_rating.\")\n",
    "\n",
    "    candidates = [\n",
    "        \"price\", \"number_of_reviews\", \"availability_365\",\n",
    "        \"calculated_host_listings_count\", \"host_total_listings_count\",\n",
    "        \"accommodates\", \"reviews_per_month\", \"minimum_nights\",\n",
    "        \"estimated_occupancy_l365d\", \"review_scores_rating\"\n",
    "    ]\n",
    "    present = [c for c in candidates if c in common_cols]\n",
    "    sel_vars = st.multiselect(\"Variables a comparar\", options=present, default=present)\n",
    "\n",
    "    if not sel_vars:\n",
    "        st.info(\"Selecciona al menos una variable.\")\n",
    "    else:\n",
    "        # Conversión segura a numérico\n",
    "        df_num = coerce_numeric_cols(df, sel_vars)\n",
    "\n",
    "        # KPIs por ciudad (mediana y promedio)\n",
    "        try:\n",
    "            kpi = (df_num.groupby(\"city\")[sel_vars]\n",
    "                   .agg(['median', 'mean'])\n",
    "                   .round(3))\n",
    "            st.dataframe(kpi, use_container_width=True)\n",
    "        except Exception as e:\n",
    "            st.warning(f\"No fue posible calcular median/mean: {e}\")\n",
    "\n",
    "        # Gráficas por variable (box + barras) con columnas numéricas\n",
    "        for v in sel_vars:\n",
    "            st.markdown(f\"**Variable:** `{v}`\")\n",
    "            c1, c2 = st.columns(2)\n",
    "\n",
    "            with c1:\n",
    "                try:\n",
    "                    fig = px.box(df_num, x=\"city\", y=v, points=\"outliers\", color=\"city\",\n",
    "                                 title=f\"Distribución de {v} por ciudad\")\n",
    "                    st.plotly_chart(fig, use_container_width=True)\n",
    "                except Exception:\n",
    "                    st.info(f\"No se pudo graficar boxplot para {v}.\")\n",
    "\n",
    "            with c2:\n",
    "                try:\n",
    "                    # SeriesGroupBy.median sin numeric_only (ya es numérico)\n",
    "                    agg = df_num.groupby(\"city\")[v].median().reset_index()\n",
    "                    fig2 = px.bar(agg, x=\"city\", y=v, title=f\"Mediana de {v} por ciudad\")\n",
    "                    st.plotly_chart(fig2, use_container_width=True)\n",
    "                except Exception:\n",
    "                    st.info(f\"No se pudo graficar barras para {v}.\")\n",
    "\n",
    "# ============================================================\n",
    "# TAB 2 - Categóricas (10 comunes)\n",
    "# ============================================================\n",
    "with tabs[1]:\n",
    "    st.subheader(\"🔠 Análisis de variables categóricas (reglas específicas)\")\n",
    "    st.caption(\"room_type y host_is_superhost en todas; neighbourhood y host_response_time solo donde existan (no en México).\")\n",
    "\n",
    "    # --- Variables canónicas a usar ---\n",
    "    canonical = [\"room_type\", \"host_is_superhost\", \"neighbourhood\", \"host_response_time\"]\n",
    "\n",
    "    # Aliases para ubicar columnas equivalentes por nombre\n",
    "    alias_map = {\n",
    "        \"room_type\": [\"room_type\", \"room\", \"tipo_habitacion\"],\n",
    "        \"host_is_superhost\": [\"host_is_superhost\", \"is_superhost\", \"superhost\"],\n",
    "        \"neighbourhood\": [\"neighbourhood\", \"neighborhood\", \"neighbourhood_cleansed\", \"barrio\", \"district\", \"zona\"],\n",
    "        \"host_response_time\": [\"host_response_time\", \"response_time\", \"tiempo_respuesta\"],\n",
    "    }\n",
    "\n",
    "    def find_col(df_local, aliases):\n",
    "        cols = list(df_local.columns)\n",
    "        low_cols = [c.lower() for c in cols]\n",
    "        # Exacta (case-insensitive)\n",
    "        for a in aliases:\n",
    "            if a.lower() in low_cols:\n",
    "                return cols[low_cols.index(a.lower())]\n",
    "        # Inclusión parcial\n",
    "        for a in aliases:\n",
    "            for i, c in enumerate(low_cols):\n",
    "                if a.lower() in c:\n",
    "                    return cols[i]\n",
    "        return None\n",
    "\n",
    "    def to_yes_no(series):\n",
    "        s = series.astype(str).str.lower().str.strip()\n",
    "        yes = {\"1\",\"t\",\"true\",\"yes\",\"si\",\"sí\",\"y\",\"s\"}\n",
    "        no  = {\"0\",\"f\",\"false\",\"no\",\"n\"}\n",
    "        return np.where(s.isin(yes), \"Sí\",\n",
    "                        np.where(s.isin(no), \"No\", series.astype(str)))\n",
    "\n",
    "    # --- Construcción del DataFrame categórico unificado ---\n",
    "    cat_frames = []\n",
    "    mapping_rows = []\n",
    "\n",
    "    for d in dfs_raw:\n",
    "        if d is None or \"city\" not in d.columns or d.empty:\n",
    "            continue\n",
    "\n",
    "        tmp = pd.DataFrame()\n",
    "        tmp[\"city\"] = d[\"city\"].astype(str)\n",
    "\n",
    "        # Detecta si el DF es de México (para excluir neighbourhood/response_time)\n",
    "        df_has_mexico = tmp[\"city\"].astype(str).str.lower().str.contains(\"mexico\").any()\n",
    "\n",
    "        # 1. room_type → siempre\n",
    "        src_room = find_col(d, alias_map[\"room_type\"])\n",
    "        tmp[\"room_type\"] = d[src_room] if src_room else np.nan\n",
    "\n",
    "        # 2. host_is_superhost → siempre (convertido a Sí/No)\n",
    "        src_super = find_col(d, alias_map[\"host_is_superhost\"])\n",
    "        if src_super:\n",
    "            tmp[\"host_is_superhost\"] = pd.Series(to_yes_no(d[src_super])).astype(\"category\")\n",
    "        else:\n",
    "            tmp[\"host_is_superhost\"] = np.nan\n",
    "\n",
    "        # 3. neighbourhood → solo donde exista y no sea México\n",
    "        src_neigh = find_col(d, alias_map[\"neighbourhood\"])\n",
    "        if (not df_has_mexico) and src_neigh:\n",
    "            tmp[\"neighbourhood\"] = d[src_neigh]\n",
    "        else:\n",
    "            tmp[\"neighbourhood\"] = np.nan\n",
    "\n",
    "        # 4. host_response_time → solo donde exista y no sea México\n",
    "        src_resp = find_col(d, alias_map[\"host_response_time\"])\n",
    "        if (not df_has_mexico) and src_resp:\n",
    "            tmp[\"host_response_time\"] = d[src_resp]\n",
    "        else:\n",
    "            tmp[\"host_response_time\"] = np.nan\n",
    "\n",
    "        cat_frames.append(tmp)\n",
    "\n",
    "        # Para mostrar en la tabla qué columnas se usaron\n",
    "        cities_str = \", \".join(sorted(tmp[\"city\"].astype(str).unique().tolist()))\n",
    "        mapping_rows.append({\n",
    "            \"Ciudad(es) en DF\": cities_str,\n",
    "            \"room_type <-\": src_room if src_room else \"❌\",\n",
    "            \"host_is_superhost <-\": src_super if src_super else \"❌\",\n",
    "            \"neighbourhood <-\": (src_neigh if (src_neigh and not df_has_mexico) else \"❌ (descartado o no existe)\"),\n",
    "            \"host_response_time <-\": (src_resp if (src_resp and not df_has_mexico) else \"❌ (descartado o no existe)\"),\n",
    "        })\n",
    "\n",
    "    if not cat_frames:\n",
    "        st.warning(\"No se pudieron construir variables categóricas desde los datasets originales.\")\n",
    "        st.stop()\n",
    "\n",
    "    df_cat_all = pd.concat(cat_frames, ignore_index=True)\n",
    "    df_cat = df_cat_all[df_cat_all[\"city\"].isin(sel_cities)].copy()\n",
    "\n",
    "    if df_cat.empty:\n",
    "        st.warning(\"No hay registros categóricos en las ciudades seleccionadas.\")\n",
    "        st.stop()\n",
    "\n",
    "    # Mostrar mapeo de columnas detectadas por dataset/ciudad\n",
    "    with st.expander(\"Ver mapeo de columnas utilizadas por dataset/ciudad\"):\n",
    "        st.dataframe(pd.DataFrame(mapping_rows), use_container_width=True)\n",
    "\n",
    "    # Filtra solo las variables realmente disponibles con datos\n",
    "    present_cats = [c for c in canonical if c in df_cat.columns and df_cat[c].notna().any()]\n",
    "\n",
    "    # Selector para activar/desactivar variables\n",
    "    sel_cats = st.multiselect(\n",
    "        \"Selecciona variables a visualizar\",\n",
    "        options=present_cats,\n",
    "        default=present_cats,\n",
    "        max_selections=len(present_cats)\n",
    "    )\n",
    "\n",
    "    if not sel_cats:\n",
    "        st.info(\"Selecciona al menos una variable categórica.\")\n",
    "    else:\n",
    "        for cat in sel_cats:\n",
    "            st.markdown(f\"### 📊 Variable: `{cat}`\")\n",
    "\n",
    "            # --- Distribución global ---\n",
    "            try:\n",
    "                dist = df_cat[cat].astype(\"category\").value_counts(dropna=False).reset_index()\n",
    "                dist.columns = [cat, \"Frecuencia\"]\n",
    "\n",
    "                col1, col2 = st.columns(2)\n",
    "                with col1:\n",
    "                    fig_bar = px.bar(\n",
    "                        dist, x=cat, y=\"Frecuencia\", color=cat,\n",
    "                        title=f\"Frecuencia global de {cat}\"\n",
    "                    )\n",
    "                    st.plotly_chart(fig_bar, use_container_width=True)\n",
    "\n",
    "                with col2:\n",
    "                    fig_pie = px.pie(\n",
    "                        dist, names=cat, values=\"Frecuencia\",\n",
    "                        title=f\"Participación global de {cat}\"\n",
    "                    )\n",
    "                    st.plotly_chart(fig_pie, use_container_width=True)\n",
    "\n",
    "            except Exception as e:\n",
    "                st.warning(f\"No se pudo graficar {cat}: {e}\")\n",
    "\n",
    "            # --- Comparativo por ciudad ---\n",
    "            try:\n",
    "                cross = (\n",
    "                    df_cat.groupby([\"city\", cat])\n",
    "                          .size()\n",
    "                          .reset_index(name=\"Conteo\")\n",
    "                )\n",
    "                fig_cross = px.bar(\n",
    "                    cross, x=\"city\", y=\"Conteo\", color=cat,\n",
    "                    barmode=\"group\", title=f\"{cat} por ciudad\"\n",
    "                )\n",
    "                st.plotly_chart(fig_cross, use_container_width=True)\n",
    "            except Exception as e:\n",
    "                st.warning(f\"No se pudo generar el comparativo de {cat} por ciudad: {e}\")\n",
    "\n",
    "        st.success(\"✅ Tab 2 configurado según reglas: room_type y superhost en todas; neighbourhood y response_time solo donde existan (no México).\")\n",
    "\n",
    "# ============================================================\n",
    "# TAB 3 - Regresión Lineal Simple (facet por ciudad, Plotly ampliado)\n",
    "# ============================================================\n",
    "with tabs[2]:\n",
    "    st.subheader(\"📐 Regresión Lineal Simple (comparativo multi-ciudad)\")\n",
    "    st.caption(\"Selecciona X e Y; se muestran todas las ciudades en facetas, con línea de ajuste y métricas R² y R.\")\n",
    "\n",
    "    # Ciudades\n",
    "    try:\n",
    "        cities_sel = sel_cities\n",
    "    except NameError:\n",
    "        cities_sel = sorted(df_all[\"city\"].dropna().unique().tolist())\n",
    "\n",
    "    # Definición segura de X e Y\n",
    "    if \"x_var\" not in locals() or \"y_var\" not in locals():\n",
    "        num_cols_all = df_all.select_dtypes(include=[\"int\", \"float\", \"Int64\", \"Float64\"]).columns.tolist()\n",
    "        fallback_numeric = [\"price\", \"number_of_reviews\", \"availability_365\", \"reviews_per_month\",\n",
    "                            \"calculated_host_listings_count\", \"host_total_listings_count\"]\n",
    "        for col in fallback_numeric:\n",
    "            if col in df_all.columns and col not in num_cols_all:\n",
    "                df_all[col] = pd.to_numeric(df_all[col], errors=\"coerce\")\n",
    "        num_cols_all = df_all.select_dtypes(include=[\"int\", \"float\", \"Int64\", \"Float64\"]).columns.tolist()\n",
    "        x_default = \"availability_365\" if \"availability_365\" in num_cols_all else (num_cols_all[0] if num_cols_all else None)\n",
    "        y_default = \"price\" if \"price\" in num_cols_all else (num_cols_all[1] if len(num_cols_all) > 1 else None)\n",
    "        x_var, y_var = x_default, y_default\n",
    "\n",
    "    num_cols_ui = df_all.select_dtypes(include=[\"int\", \"float\", \"Int64\", \"Float64\"]).columns.tolist()\n",
    "    if not num_cols_ui:\n",
    "        st.warning(\"No se detectaron columnas numéricas para realizar la regresión.\")\n",
    "        st.stop()\n",
    "\n",
    "    x_var = st.selectbox(\"Variable X (independiente)\", options=num_cols_ui,\n",
    "                         index=max(0, num_cols_ui.index(x_var) if x_var in num_cols_ui else 0),\n",
    "                         key=\"tab3_x_var\")\n",
    "    y_var = st.selectbox(\"Variable Y (dependiente)\", options=num_cols_ui,\n",
    "                         index=max(0, num_cols_ui.index(y_var) if y_var in num_cols_ui else (1 if len(num_cols_ui)>1 else 0)),\n",
    "                         key=\"tab3_y_var\")\n",
    "\n",
    "    if x_var == y_var:\n",
    "        st.info(\"Selecciona variables distintas para X e Y.\")\n",
    "        st.stop()\n",
    "\n",
    "    # Datos\n",
    "    data_lin = df_all[df_all[\"city\"].isin(cities_sel)][[\"city\", x_var, y_var]].copy()\n",
    "    data_lin[x_var] = pd.to_numeric(data_lin[x_var], errors=\"coerce\")\n",
    "    data_lin[y_var] = pd.to_numeric(data_lin[y_var], errors=\"coerce\")\n",
    "    data_lin = data_lin.dropna(subset=[x_var, y_var])\n",
    "    if data_lin.empty:\n",
    "        st.warning(\"No hay datos válidos para las variables seleccionadas en las ciudades elegidas.\")\n",
    "        st.stop()\n",
    "\n",
    "    # Ajuste por ciudad\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import r2_score\n",
    "    metrics_rows, preds_rows = [], []\n",
    "    for c in sorted(data_lin[\"city\"].dropna().unique()):\n",
    "        d = data_lin[data_lin[\"city\"] == c]\n",
    "        if d.shape[0] < 2: continue\n",
    "        X, y = d[[x_var]].values, d[y_var].values\n",
    "        lr = LinearRegression().fit(X, y)\n",
    "        yhat = lr.predict(X)\n",
    "        r2 = r2_score(y, yhat)\n",
    "        try:\n",
    "            corr = np.corrcoef(d[x_var], d[y_var])[0, 1]\n",
    "            sign = np.sign(corr) if np.isfinite(corr) else 1\n",
    "        except Exception:\n",
    "            sign = 1\n",
    "        R = sign * np.sqrt(max(r2, 0))\n",
    "        metrics_rows.append({\"city\": c, \"R2\": round(r2, 4), \"R\": round(R, 4)})\n",
    "        xx = np.linspace(d[x_var].min(), d[x_var].max(), 120).reshape(-1, 1)\n",
    "        yy = lr.predict(xx)\n",
    "        preds_rows.append(pd.DataFrame({\"city\": c, x_var: xx.ravel(), \"y_pred\": yy}))\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_rows)\n",
    "    preds_df = pd.concat(preds_rows, ignore_index=True) if preds_rows else pd.DataFrame()\n",
    "    if metrics_df.empty:\n",
    "        st.warning(\"No fue posible ajustar modelos por falta de datos suficientes.\")\n",
    "        st.stop()\n",
    "\n",
    "    # Visualización facetada grande\n",
    "    fig_sc = px.scatter(data_lin, x=x_var, y=y_var, facet_col=\"city\", facet_col_wrap=3,\n",
    "                        title=f\"Regresión Lineal Simple: {y_var} ~ {x_var}\",\n",
    "                        opacity=0.75, height=900, width=1500)\n",
    "    if not preds_df.empty:\n",
    "        fig_line = px.line(preds_df, x=x_var, y=\"y_pred\", facet_col=\"city\", facet_col_wrap=3)\n",
    "        for tr in fig_line.data: fig_sc.add_trace(tr)\n",
    "    fig_sc.update_traces(marker=dict(size=5))\n",
    "    fig_sc.update_layout(margin=dict(l=40, r=40, t=60, b=40))\n",
    "    st.plotly_chart(fig_sc, use_container_width=False)\n",
    "\n",
    "    st.markdown(\"#### 📊 Métricas por ciudad\")\n",
    "    st.dataframe(metrics_df.sort_values(\"R2\", ascending=False).reset_index(drop=True), use_container_width=True)\n",
    "    \n",
    "# ============================================================\n",
    "# TAB 4 - Regresión Múltiple (facet por ciudad, Plotly ampliado)\n",
    "# ============================================================\n",
    "with tabs[3]:\n",
    "    st.subheader(\"🧮 Regresión Múltiple (comparativo multi-ciudad)\")\n",
    "    st.caption(\"Selecciona Y y las X; facetas por ciudad (y_real vs y_pred) con métricas R² y R.\")\n",
    "\n",
    "    try:\n",
    "        cities_sel = sel_cities\n",
    "    except NameError:\n",
    "        cities_sel = sorted(df_all[\"city\"].dropna().unique().tolist())\n",
    "\n",
    "    num_cols_all = df_all.select_dtypes(include=[\"int\", \"float\", \"Int64\", \"Float64\"]).columns.tolist()\n",
    "    if not num_cols_all:\n",
    "        st.warning(\"No hay columnas numéricas para ajustar una regresión múltiple.\")\n",
    "        st.stop()\n",
    "\n",
    "    try:\n",
    "        y_var\n",
    "    except NameError:\n",
    "        y_var = \"price\" if \"price\" in num_cols_all else num_cols_all[0]\n",
    "    try:\n",
    "        x_vars\n",
    "    except NameError:\n",
    "        x_vars = [c for c in num_cols_all if c != y_var][:3] or num_cols_all[:3]\n",
    "\n",
    "    y_var = st.selectbox(\"Variable Y (dependiente)\", options=num_cols_all,\n",
    "                         index=max(0, num_cols_all.index(y_var) if y_var in num_cols_all else 0),\n",
    "                         key=\"tab4_y_var\")\n",
    "    x_vars = st.multiselect(\"Variables X (explicativas)\", options=[c for c in num_cols_all if c != y_var],\n",
    "                            default=[c for c in x_vars if c in num_cols_all and c != y_var],\n",
    "                            key=\"tab4_x_vars\")\n",
    "    if not x_vars:\n",
    "        st.info(\"Selecciona al menos una variable explicativa (X).\")\n",
    "        st.stop()\n",
    "\n",
    "    cols_needed = [\"city\", y_var] + x_vars\n",
    "    data_mlr = df_all[df_all[\"city\"].isin(cities_sel)][cols_needed].copy()\n",
    "    for c in [y_var] + x_vars:\n",
    "        data_mlr[c] = pd.to_numeric(data_mlr[c], errors=\"coerce\")\n",
    "    data_mlr = data_mlr.dropna(subset=[y_var] + x_vars)\n",
    "    if data_mlr.empty or data_mlr.shape[0] < len(x_vars) + 2:\n",
    "        st.warning(\"No hay suficientes datos válidos para ajustar la regresión múltiple.\")\n",
    "        st.stop()\n",
    "\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import r2_score\n",
    "    metrics_rows, avp_rows = [], []\n",
    "    for c in sorted(data_mlr[\"city\"].dropna().unique()):\n",
    "        d = data_mlr[data_mlr[\"city\"] == c].copy()\n",
    "        if d.shape[0] < len(x_vars) + 2: continue\n",
    "        X, y = d[x_vars].values, d[y_var].values\n",
    "        lr = LinearRegression().fit(X, y)\n",
    "        yhat = lr.predict(X)\n",
    "        r2 = r2_score(y, yhat)\n",
    "        corr = np.corrcoef(y, yhat)[0,1] if len(y) > 1 else np.nan\n",
    "        sign = np.sign(corr) if np.isfinite(corr) else 1\n",
    "        R = sign * np.sqrt(max(r2, 0))\n",
    "        metrics_rows.append({\"city\": c, \"R2\": round(r2, 4), \"R\": round(R, 4)})\n",
    "        avp_rows.append(pd.DataFrame({\"city\": c, \"y_real\": y, \"y_pred\": yhat}))\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_rows)\n",
    "    avp_df = pd.concat(avp_rows, ignore_index=True) if avp_rows else pd.DataFrame()\n",
    "    if avp_df.empty:\n",
    "        st.info(\"Sin suficientes datos por ciudad para graficar.\")\n",
    "        st.stop()\n",
    "\n",
    "    fig_mlr = px.scatter(avp_df, x=\"y_real\", y=\"y_pred\",\n",
    "                         facet_col=\"city\", facet_col_wrap=3,\n",
    "                         title=f\"Regresión Múltiple: {y_var} vs Predicción (por ciudad)\",\n",
    "                         opacity=0.75, height=900, width=1500)\n",
    "    fig_mlr.update_traces(marker=dict(size=5))\n",
    "    fig_mlr.update_layout(margin=dict(l=40, r=40, t=60, b=40))\n",
    "    st.plotly_chart(fig_mlr, use_container_width=False)\n",
    "\n",
    "    st.markdown(\"#### 📊 Métricas por ciudad\")\n",
    "    st.dataframe(metrics_df.sort_values(\"R2\", ascending=False).reset_index(drop=True), use_container_width=True)\n",
    "    \n",
    "# ============================================================\n",
    "# TAB 5 - Regresión No Lineal (facet por ciudad, Plotly ampliado)\n",
    "# ============================================================\n",
    "with tabs[4]:\n",
    "    st.subheader(\"🧭 Regresión No Lineal (comparativo multi-ciudad)\")\n",
    "    st.caption(\"Selecciona X, Y y el modelo no lineal; facetas por ciudad, línea de ajuste y métricas R² y R.\")\n",
    "\n",
    "    try:\n",
    "        cities_sel = sel_cities\n",
    "    except NameError:\n",
    "        cities_sel = sorted(df_all[\"city\"].dropna().unique().tolist())\n",
    "\n",
    "    num_cols_all = df_all.select_dtypes(include=[\"int\", \"float\", \"Int64\", \"Float64\"]).columns.tolist()\n",
    "    if not num_cols_all:\n",
    "        st.warning(\"No hay columnas numéricas para ajustar una regresión no lineal.\")\n",
    "        st.stop()\n",
    "\n",
    "    try:\n",
    "        x_var\n",
    "    except NameError:\n",
    "        x_var = \"availability_365\" if \"availability_365\" in num_cols_all else num_cols_all[0]\n",
    "    try:\n",
    "        y_var\n",
    "    except NameError:\n",
    "        y_var = \"price\" if \"price\" in num_cols_all else (num_cols_all[1] if len(num_cols_all)>1 else num_cols_all[0])\n",
    "    modelos_disp = [\"cuadrática\", \"logarítmica\", \"exponencial\", \"lineal\"]\n",
    "    try:\n",
    "        modelo\n",
    "    except NameError:\n",
    "        modelo = \"cuadrática\"\n",
    "\n",
    "    x_var = st.selectbox(\"Variable X (independiente)\", options=num_cols_all,\n",
    "                         index=max(0, num_cols_all.index(x_var) if x_var in num_cols_all else 0),\n",
    "                         key=\"tab5_x_var\")\n",
    "    y_var = st.selectbox(\"Variable Y (dependiente)\", options=num_cols_all,\n",
    "                         index=max(0, num_cols_all.index(y_var) if y_var in num_cols_all else (1 if len(num_cols_all)>1 else 0)),\n",
    "                         key=\"tab5_y_var\")\n",
    "    modelo = st.selectbox(\"Modelo\", options=modelos_disp,\n",
    "                          index=modelos_disp.index(modelo) if modelo in modelos_disp else 0,\n",
    "                          key=\"tab5_modelo\")\n",
    "\n",
    "    if x_var == y_var:\n",
    "        st.info(\"Selecciona variables distintas para X e Y.\")\n",
    "        st.stop()\n",
    "\n",
    "    data_nl = df_all[df_all[\"city\"].isin(cities_sel)][[\"city\", x_var, y_var]].copy()\n",
    "    data_nl[x_var] = pd.to_numeric(data_nl[x_var], errors=\"coerce\")\n",
    "    data_nl[y_var] = pd.to_numeric(data_nl[y_var], errors=\"coerce\")\n",
    "    data_nl = data_nl.dropna(subset=[x_var, y_var])\n",
    "    if data_nl.empty:\n",
    "        st.warning(\"No hay datos válidos para las variables seleccionadas.\")\n",
    "        st.stop()\n",
    "\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import r2_score\n",
    "    metrics_rows, preds_rows = [], []\n",
    "\n",
    "    def fit_predict_model(d, modelo_sel):\n",
    "        X = d[[x_var]].values\n",
    "        y = d[y_var].values\n",
    "        if modelo_sel == \"cuadrática\":\n",
    "            X_ = np.c_[X, X**2]; lr = LinearRegression().fit(X_, y); return lr, (lambda xx: lr.predict(np.c_[xx, xx**2]))\n",
    "        elif modelo_sel == \"logarítmica\":\n",
    "            if (d[x_var] <= 0).any(): return None, None\n",
    "            X_ = np.log(X); lr = LinearRegression().fit(X_, y); return lr, (lambda xx: lr.predict(np.log(xx)))\n",
    "        elif modelo_sel == \"exponencial\":\n",
    "            if (d[y_var] <= 0).any(): return None, None\n",
    "            lr = LinearRegression().fit(X, np.log(y)); return lr, (lambda xx: np.exp(lr.predict(xx)))\n",
    "        else:\n",
    "            lr = LinearRegression().fit(X, y); return lr, (lambda xx: lr.predict(xx))\n",
    "\n",
    "    for c in sorted(data_nl[\"city\"].dropna().unique()):\n",
    "        d = data_nl[data_nl[\"city\"] == c].copy()\n",
    "        if d.shape[0] < 2: continue\n",
    "        lr, f_pred = fit_predict_model(d, modelo)\n",
    "        if lr is None: continue\n",
    "        X = d[[x_var]].values; y = d[y_var].values; yhat = f_pred(X)\n",
    "        r2 = r2_score(y, yhat)\n",
    "        corr = np.corrcoef(d[x_var], y)[0,1] if len(d)>1 else np.nan\n",
    "        sign = np.sign(corr) if np.isfinite(corr) else 1\n",
    "        R = sign * np.sqrt(max(r2, 0))\n",
    "        metrics_rows.append({\"city\": c, \"R2\": round(r2,4), \"R\": round(R,4)})\n",
    "        xx = np.linspace(d[x_var].min(), d[x_var].max(), 120).reshape(-1,1)\n",
    "        yy = f_pred(xx)\n",
    "        preds_rows.append(pd.DataFrame({\"city\": c, x_var: xx.ravel(), \"y_pred\": yy}))\n",
    "\n",
    "    metrics_df = pd.DataFrame(metrics_rows)\n",
    "    preds_df = pd.concat(preds_rows, ignore_index=True) if preds_rows else pd.DataFrame()\n",
    "\n",
    "    fig_sc = px.scatter(data_nl, x=x_var, y=y_var, facet_col=\"city\", facet_col_wrap=3,\n",
    "                        title=f\"Regresión No Lineal ({modelo}): {y_var} ~ {x_var}\",\n",
    "                        opacity=0.75, height=900, width=1500)\n",
    "    if not preds_df.empty:\n",
    "        fig_line = px.line(preds_df, x=x_var, y=\"y_pred\",\n",
    "                           facet_col=\"city\", facet_col_wrap=3)\n",
    "        for tr in fig_line.data: fig_sc.add_trace(tr)\n",
    "    fig_sc.update_traces(marker=dict(size=5))\n",
    "    fig_sc.update_layout(margin=dict(l=40, r=40, t=60, b=40))\n",
    "    st.plotly_chart(fig_sc, use_container_width=False)\n",
    "\n",
    "    st.markdown(\"#### 📊 Métricas por ciudad\")\n",
    "    if metrics_df.empty:\n",
    "        st.info(\"No se pudieron calcular métricas (revisa datos/modelo).\")\n",
    "    else:\n",
    "        st.dataframe(metrics_df.sort_values(\"R2\", ascending=False).reset_index(drop=True), use_container_width=True)\n",
    "        \n",
    "# ============================================================\n",
    "# TAB 6 - Regresión Logística (facet por ciudad, Plotly ampliado)\n",
    "# ============================================================\n",
    "with tabs[5]:\n",
    "    st.subheader(\"🧪 Regresión Logística (comparativo multi-ciudad)\")\n",
    "    st.caption(\"Selecciona la Y binaria y las X; curvas ROC por ciudad en facetas y métricas AUC/Precision/Recall/F1.\")\n",
    "\n",
    "    try:\n",
    "        cities_sel = sel_cities\n",
    "    except NameError:\n",
    "        cities_sel = sorted(df_all[\"city\"].dropna().unique().tolist())\n",
    "\n",
    "    # Y binaria y X_vars seguros\n",
    "    try:\n",
    "        y_bin\n",
    "    except NameError:\n",
    "        y_bin = \"host_is_superhost\" if \"host_is_superhost\" in df_all.columns else None\n",
    "\n",
    "    num_cols_all = df_all.select_dtypes(include=[\"int\", \"float\", \"Int64\", \"Float64\"]).columns.tolist()\n",
    "    try:\n",
    "        X_vars\n",
    "    except NameError:\n",
    "        X_vars = [c for c in [\"price\",\"availability_365\",\"number_of_reviews\"] if c in num_cols_all] or num_cols_all[:2]\n",
    "\n",
    "    # Selector de Y binaria\n",
    "    if y_bin is None or y_bin not in df_all.columns:\n",
    "        bin_candidates = [c for c in df_all.columns if df_all[c].dropna().astype(str).str.lower().isin([\"0\",\"1\",\"t\",\"f\",\"true\",\"false\",\"yes\",\"no\",\"si\",\"sí\"]).any()]\n",
    "        if not bin_candidates:\n",
    "            st.warning(\"No se detectó una columna binaria para Y. Define y_bin o crea una binarización en tu Tab de Logística.\")\n",
    "            st.stop()\n",
    "        y_bin = st.selectbox(\"Variable Y binaria\", options=bin_candidates, index=0, key=\"tab6_y_bin\")\n",
    "    else:\n",
    "        all_opts = [y_bin] + [c for c in df_all.columns if c != y_bin]\n",
    "        y_bin = st.selectbox(\"Variable Y binaria\", options=all_opts, index=0, key=\"tab6_y_bin_fixed\")\n",
    "\n",
    "    # Select Xs\n",
    "    X_vars = st.multiselect(\"Variables X (explicativas)\", options=[c for c in num_cols_all if c != y_bin],\n",
    "                            default=[x for x in X_vars if x in num_cols_all and x != y_bin],\n",
    "                            key=\"tab6_x_vars\")\n",
    "    if not X_vars:\n",
    "        st.info(\"Selecciona al menos una variable explicativa (X).\")\n",
    "        st.stop()\n",
    "\n",
    "    # Parámetros de entrenamiento\n",
    "    try:\n",
    "        class_weight_opt\n",
    "    except NameError:\n",
    "        class_weight_opt = \"balanced\"\n",
    "    try:\n",
    "        threshold_opt\n",
    "    except NameError:\n",
    "        threshold_opt = 0.5\n",
    "\n",
    "    class_weight_opt = st.selectbox(\"class_weight\", options=[\"none\",\"balanced\"],\n",
    "                                    index=1 if class_weight_opt in [\"balanced\"] else 0,\n",
    "                                    key=\"tab6_class_weight\")\n",
    "    threshold_opt = st.number_input(\"Umbral de clasificación (0–1)\", min_value=0.0, max_value=1.0,\n",
    "                                    value=float(threshold_opt), step=0.05, key=\"tab6_threshold\")\n",
    "\n",
    "    # Preparación de datos\n",
    "    cols_needed = [\"city\", y_bin] + X_vars\n",
    "    data_log = df_all[df_all[\"city\"].isin(cities_sel)][cols_needed].copy()\n",
    "\n",
    "    # Y binaria robusta\n",
    "    y_raw = data_log[y_bin].astype(str).str.strip().str.lower()\n",
    "    y_num = np.where(y_raw.isin([\"1\",\"t\",\"true\",\"yes\",\"si\",\"sí\",\"y\",\"s\"]), 1,\n",
    "                     np.where(y_raw.isin([\"0\",\"f\",\"false\",\"no\",\"n\"]), 0, np.nan))\n",
    "    data_log[y_bin] = pd.to_numeric(y_num, errors=\"coerce\")\n",
    "\n",
    "    # X numérico\n",
    "    for c in X_vars:\n",
    "        data_log[c] = pd.to_numeric(data_log[c], errors=\"coerce\")\n",
    "\n",
    "    data_log = data_log.dropna(subset=[y_bin] + X_vars)\n",
    "    if data_log.empty or data_log[y_bin].nunique() < 2:\n",
    "        st.warning(\"No hay suficientes datos/variabilidad en la Y binaria para ajustar la logística.\")\n",
    "        st.stop()\n",
    "\n",
    "    # Ajuste por ciudad + ROC facet\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_fscore_support\n",
    "\n",
    "    metrics_rows, roc_rows = [], []\n",
    "    for c in sorted(data_log[\"city\"].dropna().unique()):\n",
    "        d = data_log[data_log[\"city\"] == c].copy()\n",
    "        if d[y_bin].nunique() < 2 or d.shape[0] < len(X_vars) + 2: continue\n",
    "\n",
    "        X, y = d[X_vars].values, d[y_bin].astype(int).values\n",
    "        cw = None if class_weight_opt in [\"none\", None, \"\"] else class_weight_opt\n",
    "        lr = LogisticRegression(max_iter=500, class_weight=cw)\n",
    "        lr.fit(X, y)\n",
    "        proba = lr.predict_proba(X)[:, 1]\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y, proba)\n",
    "        auc = roc_auc_score(y, proba)\n",
    "        roc_rows.append(pd.DataFrame({\"city\": c, \"fpr\": fpr, \"tpr\": tpr, \"auc\": auc}))\n",
    "\n",
    "        thr = float(threshold_opt)\n",
    "        yhat = (proba >= thr).astype(int)\n",
    "        prec, rec, f1, _ = precision_recall_fscore_support(y, yhat, average=\"binary\", zero_division=0)\n",
    "        metrics_rows.append({\"city\": c, \"AUC\": round(auc,4), \"Precision\": round(prec,4), \"Recall\": round(rec,4), \"F1\": round(f1,4)})\n",
    "\n",
    "    roc_df = pd.concat(roc_rows, ignore_index=True) if roc_rows else pd.DataFrame()\n",
    "    metrics_df = pd.DataFrame(metrics_rows) if metrics_rows else pd.DataFrame(columns=[\"city\",\"AUC\",\"Precision\",\"Recall\",\"F1\"])\n",
    "\n",
    "    if roc_df.empty:\n",
    "        st.info(\"No hay suficientes datos para graficar ROC por ciudad.\")\n",
    "    else:\n",
    "        fig_roc = px.area(roc_df, x=\"fpr\", y=\"tpr\",\n",
    "                          facet_col=\"city\", facet_col_wrap=3,\n",
    "                          title=\"Regresión Logística: Curvas ROC por ciudad\",\n",
    "                          hover_data={\"auc\":\":.3f\"}, height=900, width=1500)\n",
    "        fig_roc.update_layout(margin=dict(l=40, r=40, t=60, b=40))\n",
    "        st.plotly_chart(fig_roc, use_container_width=False)\n",
    "\n",
    "    st.markdown(\"#### 📊 Métricas por ciudad\")\n",
    "    st.dataframe(metrics_df.sort_values(\"AUC\", ascending=False).reset_index(drop=True),\n",
    "                 use_container_width=True)\n",
    "\n",
    "# ============================================================\n",
    "# TAB 7 - Insights & Propuestas\n",
    "# ============================================================\n",
    "with tabs[6]:\n",
    "    st.subheader(\"📊 Insights y Recomendaciones Estratégicas\")\n",
    "    st.caption(\"Comparación de medias entre ciudades usando variables reconstruidas desde los datasets originales (sin intersección). Incluye % de Superhosts (T).\")\n",
    "\n",
    "    import re, unicodedata\n",
    "\n",
    "    # ---- Utilidades robustas ----\n",
    "    def _norm_txt(s: str) -> str:\n",
    "        s = str(s)\n",
    "        s = unicodedata.normalize(\"NFKD\", s)\n",
    "        s = \"\".join(ch for ch in s if not unicodedata.combining(ch))\n",
    "        return s.strip().lower()\n",
    "\n",
    "    def is_mex(name: str) -> bool:\n",
    "        n = _norm_txt(name)\n",
    "        return bool(\n",
    "            re.search(r\"^mex\", n) or\n",
    "            re.search(r\"ciudad\\s*de\\s*mex\", n) or\n",
    "            re.search(r\"\\bcdmx\\b\", n) or\n",
    "            re.fullmatch(r\"mx\", n)\n",
    "        )\n",
    "\n",
    "    def find_col(df_local, aliases):\n",
    "        cols = list(df_local.columns)\n",
    "        low = [c.strip().lower() for c in cols]\n",
    "        # exacta\n",
    "        for a in aliases:\n",
    "            a2 = a.strip().lower()\n",
    "            if a2 in low:\n",
    "                return cols[low.index(a2)]\n",
    "        # inclusión parcial\n",
    "        for a in aliases:\n",
    "            a2 = a.strip().lower()\n",
    "            for i, c in enumerate(low):\n",
    "                if a2 in c:\n",
    "                    return cols[i]\n",
    "        return None\n",
    "\n",
    "    def clean_numeric_like(series):\n",
    "        s = series.astype(str).str.replace(r\"[^\\d,.\\-]\", \"\", regex=True)\n",
    "        mask_coma_decimal = ~s.str.contains(r\"\\.\") & s.str.contains(\",\")\n",
    "        s.loc[mask_coma_decimal] = s.loc[mask_coma_decimal].str.replace(\",\", \".\", regex=False)\n",
    "        s = s.str.replace(\",\", \"\", regex=False)\n",
    "        return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "    # ---- Aliases por variable ----\n",
    "    alias = {\n",
    "        \"host_is_superhost\": [\"host_is_superhost\", \"is_superhost\", \"superhost\"],\n",
    "        \"host_response_time\": [\"host_response_time\", \"response_time\", \"tiempo_respuesta\"],\n",
    "        \"calculated_host_listings_count\": [\"calculated_host_listings_count\", \"host_total_listings_count\"],\n",
    "        \"price\": [\"price\", \"precio\"],\n",
    "        \"number_of_reviews\": [\"number_of_reviews\", \"reviews\"],\n",
    "        \"availability_365\": [\"availability_365\"],\n",
    "    }\n",
    "\n",
    "    # ---- Reconstrucción desde dfs_raw ----\n",
    "    recs = []       # filas unificadas\n",
    "    mappings = []   # mapeo por dataset\n",
    "\n",
    "    for d in dfs_raw:\n",
    "        if d is None or d.empty or \"city\" not in d.columns:\n",
    "            continue\n",
    "        df_local = d.copy()\n",
    "        df_local.columns = [str(c).strip() for c in df_local.columns]\n",
    "\n",
    "        tmp = pd.DataFrame()\n",
    "        tmp[\"city\"] = df_local[\"city\"].astype(str)\n",
    "\n",
    "        # host_is_superhost (con regla para México)\n",
    "        col_hsh = find_col(df_local, alias[\"host_is_superhost\"])\n",
    "        if col_hsh:\n",
    "            raw = df_local[col_hsh].astype(str).str.strip().str.lower()\n",
    "            # máscara México\n",
    "            mex_mask = tmp[\"city\"].map(is_mex).fillna(False)\n",
    "\n",
    "            # México: SOLO T/F/1/0 -> map estricta; resto NaN\n",
    "            map_mex = {\"t\": 1, \"f\": 0, \"1\": 1, \"0\": 0}\n",
    "            tmp.loc[mex_mask, \"host_is_superhost_num\"] = raw[mex_mask].map(map_mex)\n",
    "\n",
    "            # Otras ciudades: mapeo flexible clásico\n",
    "            oth = ~mex_mask\n",
    "            tmp.loc[oth, \"host_is_superhost_num\"] = np.where(\n",
    "                raw[oth].isin([\"t\",\"true\",\"1\",\"yes\",\"si\",\"sí\",\"y\",\"s\"]), 1,\n",
    "                np.where(raw[oth].isin([\"f\",\"false\",\"0\",\"no\",\"n\"]), 0, np.nan)\n",
    "            )\n",
    "\n",
    "            # También versión F/T para diagnóstico y visual\n",
    "            tmp[\"host_is_superhost_str\"] = tmp[\"host_is_superhost_num\"].map({1.0: \"T\", 0.0: \"F\"})\n",
    "        else:\n",
    "            tmp[\"host_is_superhost_num\"] = np.nan\n",
    "            tmp[\"host_is_superhost_str\"] = np.nan\n",
    "\n",
    "        # host_response_time -> ordinal 4..1\n",
    "        col_rt = find_col(df_local, alias[\"host_response_time\"])\n",
    "        if col_rt:\n",
    "            m = {\n",
    "                \"within an hour\": 4, \"within a few hours\": 3,\n",
    "                \"within a day\": 2, \"a few days or more\": 1\n",
    "            }\n",
    "            tmp[\"host_response_time\"] = (\n",
    "                df_local[col_rt].astype(str).str.strip().str.lower().map(m)\n",
    "            )\n",
    "        else:\n",
    "            tmp[\"host_response_time\"] = np.nan\n",
    "\n",
    "        # calculated_host_listings_count\n",
    "        col_chl = find_col(df_local, alias[\"calculated_host_listings_count\"])\n",
    "        if col_chl:\n",
    "            tmp[\"calculated_host_listings_count\"] = pd.to_numeric(df_local[col_chl], errors=\"coerce\")\n",
    "        else:\n",
    "            tmp[\"calculated_host_listings_count\"] = np.nan\n",
    "\n",
    "        # price (limpieza general; NaN se ignoran en medias; caso Valencia ya cubierto)\n",
    "        col_price = find_col(df_local, alias[\"price\"])\n",
    "        if col_price:\n",
    "            tmp[\"price\"] = clean_numeric_like(df_local[col_price])\n",
    "        else:\n",
    "            tmp[\"price\"] = np.nan\n",
    "\n",
    "        # number_of_reviews\n",
    "        col_nor = find_col(df_local, alias[\"number_of_reviews\"])\n",
    "        if col_nor:\n",
    "            tmp[\"number_of_reviews\"] = pd.to_numeric(df_local[col_nor], errors=\"coerce\")\n",
    "        else:\n",
    "            tmp[\"number_of_reviews\"] = np.nan\n",
    "\n",
    "        # availability_365\n",
    "        col_av = find_col(df_local, alias[\"availability_365\"])\n",
    "        if col_av:\n",
    "            tmp[\"availability_365\"] = pd.to_numeric(df_local[col_av], errors=\"coerce\")\n",
    "        else:\n",
    "            tmp[\"availability_365\"] = np.nan\n",
    "\n",
    "        recs.append(tmp)\n",
    "\n",
    "        # mapeo informativo\n",
    "        maps = {\n",
    "            \"Ciudad(es) en DF\": \", \".join(sorted(tmp[\"city\"].astype(str).unique())),\n",
    "            \"host_is_superhost <-\": col_hsh if col_hsh else \"❌\",\n",
    "            \"host_response_time <-\": col_rt if col_rt else \"❌\",\n",
    "            \"calculated_host_listings_count <-\": col_chl if col_chl else \"❌\",\n",
    "            \"price <-\": col_price if col_price else \"❌\",\n",
    "            \"number_of_reviews <-\": col_nor if col_nor else \"❌\",\n",
    "            \"availability_365 <-\": col_av if col_av else \"❌\",\n",
    "        }\n",
    "        mappings.append(maps)\n",
    "\n",
    "    if not recs:\n",
    "        st.warning(\"No hay datos disponibles para generar insights.\")\n",
    "        st.stop()\n",
    "\n",
    "    df_ins = pd.concat(recs, ignore_index=True)\n",
    "    # Filtra por las ciudades seleccionadas\n",
    "    df_ins = df_ins[df_ins[\"city\"].isin(sel_cities)].copy()\n",
    "\n",
    "    # ---- Diagnóstico de mapeos ----\n",
    "    with st.expander(\"🔎 Mapeo de columnas utilizadas por dataset\"):\n",
    "        st.dataframe(pd.DataFrame(mappings), use_container_width=True)\n",
    "\n",
    "    # ---- Tabla de diagnóstico Superhosts F/T por ciudad ----\n",
    "    with st.expander(\"🔍 Distribución F/T por ciudad (host_is_superhost)\"):\n",
    "        if \"host_is_superhost_str\" in df_ins.columns:\n",
    "            diag = (\n",
    "                df_ins.groupby([\"city\", \"host_is_superhost_str\"])\n",
    "                .size()\n",
    "                .unstack(fill_value=0)\n",
    "                .rename(columns={\"F\": \"F (No)\", \"T\": \"T (Sí)\"})\n",
    "            )\n",
    "            st.dataframe(diag, use_container_width=True)\n",
    "\n",
    "    # ---- Cálculo de medias por ciudad ----\n",
    "    metrics = [\"host_is_superhost_num\", \"host_response_time\",\n",
    "               \"calculated_host_listings_count\", \"price\",\n",
    "               \"number_of_reviews\", \"availability_365\"]\n",
    "\n",
    "    summary = {}\n",
    "    for v in metrics:\n",
    "        if v in df_ins.columns:\n",
    "            df_ins[v] = pd.to_numeric(df_ins[v], errors=\"coerce\")\n",
    "            mean_v = df_ins.groupby(\"city\")[v].mean().round(2)\n",
    "            if mean_v.notna().any():\n",
    "                summary[v] = mean_v\n",
    "\n",
    "    if not summary:\n",
    "        st.warning(\"No fue posible calcular medias (todas las series vacías).\")\n",
    "        st.stop()\n",
    "\n",
    "    df_summary = pd.DataFrame(summary).sort_index()\n",
    "\n",
    "    # Porcentaje de Superhosts (T) por ciudad\n",
    "    if \"host_is_superhost_num\" in df_summary.columns:\n",
    "        df_summary[\"%_superhosts\"] = (df_summary[\"host_is_superhost_num\"] * 100).round(1)\n",
    "\n",
    "    st.markdown(\"### 📈 Comparativo de medias entre ciudades\")\n",
    "    st.dataframe(df_summary, use_container_width=True)\n",
    "\n",
    "    # ---- Gráficas ----\n",
    "    # Hosts\n",
    "    st.markdown(\"#### 🧑‍💼 Métricas de Hosts\")\n",
    "    for v, title in [\n",
    "        (\"host_is_superhost_num\", \"% Superhosts (promedio 0/1)\"),\n",
    "        (\"host_response_time\", \"Rapidez de respuesta (4=mejor)\"),\n",
    "        (\"calculated_host_listings_count\", \"Propiedades por host (promedio)\"),\n",
    "    ]:\n",
    "        if v in df_summary.columns:\n",
    "            fig = px.bar(df_summary.reset_index(), x=\"city\", y=v, color=\"city\",\n",
    "                         title=f\"{title} — promedio por ciudad\")\n",
    "            st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    # Hospedaje\n",
    "    st.markdown(\"#### 🏠 Métricas de Hospedaje\")\n",
    "    for v, title in [\n",
    "        (\"price\", \"Precio promedio\"),\n",
    "        (\"number_of_reviews\", \"Reseñas promedio\"),\n",
    "        (\"availability_365\", \"Disponibilidad promedio (días)\"),\n",
    "    ]:\n",
    "        if v in df_summary.columns:\n",
    "            fig = px.bar(df_summary.reset_index(), x=\"city\", y=v, color=\"city\",\n",
    "                         title=f\"{title} — promedio por ciudad\")\n",
    "            st.plotly_chart(fig, use_container_width=True)\n",
    "\n",
    "    # ---- Recomendaciones ----\n",
    "    st.markdown(\"### 🧭 Recomendaciones Estratégicas\")\n",
    "    recs = []\n",
    "    if \"%_superhosts\" in df_summary.columns:\n",
    "        minc = df_summary[\"%_superhosts\"].idxmin()\n",
    "        recs.append(f\"- **{minc}**: impulsar la ruta a Superhost (mentoría + checklist de amenities) para elevar el % de superhosts.\")\n",
    "    if \"host_response_time\" in df_summary.columns:\n",
    "        minr = df_summary[\"host_response_time\"].idxmin()\n",
    "        recs.append(f\"- **{minr}**: activar respuestas automáticas y recordatorios para mejorar tiempos de respuesta de hosts.\")\n",
    "    if \"availability_365\" in df_summary.columns:\n",
    "        maxa = df_summary[\"availability_365\"].idxmax()\n",
    "        recs.append(f\"- **{maxa}**: aplicar pricing dinámico y promos de temporada baja para reducir vacancia anual.\")\n",
    "    if \"price\" in df_summary.columns:\n",
    "        maxp = df_summary[\"price\"].idxmax()\n",
    "        recs.append(f\"- **{maxp}**: consolidar oferta premium y low-budget (bundles: late checkout, limpieza) como estrategia comercial.\")\n",
    "    if \"number_of_reviews\" in df_summary.columns:\n",
    "        minrv = df_summary[\"number_of_reviews\"].idxmin()\n",
    "        recs.append(f\"- **{minrv}**: campañas de visibilidad + recordatorios post-estancia para aumentar reseñas.\")\n",
    "    if \"calculated_host_listings_count\" in df_summary.columns:\n",
    "        maxh = df_summary[\"calculated_host_listings_count\"].idxmax()\n",
    "        recs.append(f\"- **{maxh}**: estrategia de diversificación de alojamientos.\")\n",
    "\n",
    "    for r in recs:\n",
    "        st.markdown(r)\n",
    "\n",
    "    st.success(\"✅ host_is_superhost de MÉXICO tomado correctamente (solo T/F/1/0) y % de T por ciudad calculado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
